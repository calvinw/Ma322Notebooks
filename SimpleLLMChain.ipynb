{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Simple LLM Chain\n",
        "\n",
        "### Put Your OPENROUTER_API_KEY here"
      ],
      "id": "c7d7c8a8-26e7-47e9-b658-8eaa4fdd2f59"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"OPENROUTER_API_KEY\"] = \"paste_your_api_key_here\""
      ],
      "id": "42a9df5b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip3 install langchain langchain_openai"
      ],
      "id": "4d9977da"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "try:\n",
        "    model_name\n",
        "except NameError:\n",
        "    model_name=\"openai/gpt-4o-mini\"\n",
        "\n",
        "print(\"Model Name:\", model_name)\n",
        "print(\"Provider:\", \"OpenRouter AI\")\n",
        "\n",
        "llm=ChatOpenAI(model_name=model_name,\n",
        "               openai_api_key=os.environ.get(\"OPENROUTER_API_KEY\"),\n",
        "               openai_api_base=\"https://openrouter.ai/api/v1\")"
      ],
      "id": "81359a0d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import textwrap\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "def wrap_text(text, max_width=80):\n",
        "    \"\"\"\n",
        "    Wraps the text to the specified max_width, preserving line breaks and formatting.\n",
        "    \"\"\"\n",
        "    text = text.lstrip()\n",
        "    lines = text.splitlines()  # Split the text into lines\n",
        "    wrapped_lines = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Skip empty lines\n",
        "            wrapped_line = textwrap.fill(line, max_width, initial_indent='', subsequent_indent='')\n",
        "            wrapped_lines.extend(wrapped_line.splitlines())  # Preserve line breaks\n",
        "        else:\n",
        "            wrapped_lines.append('')  # Keep empty lines\n",
        "    return '\\n'.join(wrapped_lines)\n",
        "\n",
        "def print_prompt_and_response(prompt, response):\n",
        "    print(\"Prompt: \")\n",
        "    print(wrap_text(prompt))\n",
        "    print(\"\")\n",
        "    print(\"Response: \")\n",
        "    print(response)\n",
        "\n",
        "def print_messages_and_response(messages, response):\n",
        "    prompt = ChatPromptTemplate(messages=messages)\n",
        "    print_prompt_and_response(prompt.format(), response)\n",
        "\n",
        "def get_completion(prompt, temperature=0.0):\n",
        "    response = llm.invoke(prompt, temperature=temperature)\n",
        "    wrapped_response = wrap_text(response.content)\n",
        "    return wrapped_response\n",
        "\n",
        "def get_completion_messages(messages, temperature=0.0):\n",
        "    response=llm.invoke(messages, temperature=temperature)\n",
        "    wrapped_response = wrap_text(response.content)\n",
        "    return wrapped_response"
      ],
      "id": "2b466c82"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Description of Simple LLM Chain\n",
        "\n",
        "Here we build a simple LLM Chain that makes two calls to the LLM. The\n",
        "second step depends on the answer from the first step. This shows the\n",
        "idea of a chain.\n",
        "\n",
        "### Step 1: What is the city {person} is from?"
      ],
      "id": "f5242e1c-3f62-42c0-ac2e-cd8b692e5bc5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "city_template=\"\"\"\n",
        "Where is {person} from? Give just the city name\n",
        "\"\"\"\n",
        "\n",
        "city_prompt = city_template.format(person=\"Sean Connery\")\n",
        "city_response = get_completion(city_prompt)\n",
        "print(city_response)"
      ],
      "id": "4721d02e"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2: What country is {city} in?"
      ],
      "id": "3cf66dc2-e672-47f0-86c4-29a16c8976b1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "country_template=\"\"\"\n",
        "What country is the city {city} in? Respond in {language} with just the name.\n",
        "\"\"\"\n",
        "\n",
        "country_prompt = country_template.format(city=city_response,\n",
        "                                         language=\"French\")\n",
        "country_response = get_completion(country_prompt)\n",
        "print(country_response)"
      ],
      "id": "1d7eb4bd"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3: Final Report\n",
        "\n",
        "Sometimes we will want to print out a summary of the responses we get in\n",
        "a chain. This may or may not include the prompts we give as well. We can\n",
        "just use a template for this as well, even though this is not a prompt,\n",
        "it is a convenient way to set up a printed version of the information."
      ],
      "id": "c5368ffb-1142-481f-9f5c-38d87c59c12e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "report_template=\"\"\"\n",
        "## Final Report\n",
        "\n",
        "### Person\n",
        "{person}\n",
        "\n",
        "### City\n",
        "{city}\n",
        "\n",
        "### Language\n",
        "{language}\n",
        "\n",
        "### Country\n",
        "{country}\n",
        "\"\"\"\n",
        "\n",
        "# We pass the format function the values we used or got from the LLM\n",
        "report = report_template.format(person = \"Sean Connery\",\n",
        "                                city = city_response,\n",
        "                                language = \"French\",\n",
        "                                country= country_response)\n",
        "print(report)"
      ],
      "id": "1b2cb8b6"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    }
  }
}