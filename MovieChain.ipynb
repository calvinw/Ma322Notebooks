{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Movie Chain\n",
        "\n",
        "### Put Your OPENROUTER_API_KEY here"
      ],
      "id": "de9e0e74-499d-4f32-843a-d326e6121108"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"OPENROUTER_API_KEY\"] = \"paste_your_api_key_here\""
      ],
      "id": "da625d5c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip3 install langchain langchain_openai"
      ],
      "id": "986241c4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "try:\n",
        "    model_name\n",
        "except NameError:\n",
        "    model_name=\"openai/gpt-4o-mini\"\n",
        "\n",
        "print(\"Model Name:\", model_name)\n",
        "print(\"Provider:\", \"OpenRouter AI\")\n",
        "\n",
        "llm=ChatOpenAI(model_name=model_name,\n",
        "               openai_api_key=os.environ.get(\"OPENROUTER_API_KEY\"),\n",
        "               openai_api_base=\"https://openrouter.ai/api/v1\")"
      ],
      "id": "ed5856e7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import textwrap\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "from IPython.display import display, clear_output, Markdown\n",
        "from ipywidgets import widgets, Layout\n",
        "\n",
        "conversation_output = widgets.Output()\n",
        "messages = []\n",
        "\n",
        "def run_chatbot(system_prompt, initial_message):\n",
        "    global messages \n",
        "    messages = [ {'role':'system', 'content': system_prompt} ]\n",
        "    conversation_output.clear_output()\n",
        "\n",
        "    messages.append({'role': 'assistant', 'content': initial_message})\n",
        "\n",
        "    text_input = widgets.Text(\n",
        "        placeholder='Type your message here...',\n",
        "        layout=widgets.Layout(width='50%')\n",
        "    )\n",
        "    submit_button = widgets.Button(description=\"Send\")\n",
        "\n",
        "    input_box = widgets.HBox([text_input, submit_button])\n",
        "    display(conversation_output, input_box)\n",
        "\n",
        "    def on_submit_click(b):\n",
        "        message = text_input.value\n",
        "        text_input.value = ''  # Clear the input field\n",
        "\n",
        "        with conversation_output:\n",
        "            display(Markdown(f\"**User**: {message}\"))\n",
        "            messages.append({'role': 'user', 'content': message})\n",
        "            response = get_completion_messages(messages)\n",
        "            display(Markdown(f\"**AI**: {response}\"))\n",
        "            messages.append({'role': 'assistant', 'content': response})\n",
        "\n",
        "    submit_button.on_click(on_submit_click)\n",
        "\n",
        "    # Display initial AI message\n",
        "    with conversation_output:\n",
        "        display(Markdown(f\"**AI**: {initial_message}\"))\n",
        "\n",
        "def wrap_text(text, max_width=80):\n",
        "    \"\"\"\n",
        "    Wraps the text to the specified max_width, preserving line breaks and formatting.\n",
        "    \"\"\"\n",
        "    text = text.lstrip()\n",
        "    lines = text.splitlines()  # Split the text into lines\n",
        "    wrapped_lines = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Skip empty lines\n",
        "            wrapped_line = textwrap.fill(line, max_width, initial_indent='', subsequent_indent='')\n",
        "            wrapped_lines.extend(wrapped_line.splitlines())  # Preserve line breaks\n",
        "        else:\n",
        "            wrapped_lines.append('')  # Keep empty lines\n",
        "    return '\\n'.join(wrapped_lines)\n",
        "\n",
        "def print_messages():\n",
        "    for message in messages:\n",
        "        role = message['role']\n",
        "        content = message['content']\n",
        "        \n",
        "        if role == 'system':\n",
        "            print(\"System:\")\n",
        "            print(\"-\" * 40)\n",
        "            print(content)\n",
        "        elif role == 'user':\n",
        "            print(\"User: \", end=\"\")\n",
        "            print(wrap_text(content))\n",
        "        elif role == 'assistant':\n",
        "            print(\"Assistant: \", end=\"\")\n",
        "            print(wrap_text(content))\n",
        "        print()  # Add an extra newline for spacing\n",
        "\n",
        "def print_prompt_and_response(prompt, response):\n",
        "    print(\"Prompt: \")\n",
        "    print(wrap_text(prompt))\n",
        "    print(\"\")\n",
        "    print(\"Response: \")\n",
        "    print(response)\n",
        "\n",
        "def print_messages_and_response(messages, response):\n",
        "    prompt = ChatPromptTemplate(messages=messages)\n",
        "    print_prompt_and_response(prompt.format(), response)\n",
        "\n",
        "def get_completion(prompt, temperature=0.0):\n",
        "    response = llm.invoke(prompt, temperature=temperature)\n",
        "    wrapped_response = wrap_text(response.content)\n",
        "    return wrapped_response\n",
        "\n",
        "def get_completion_messages(messages, temperature=0.0):\n",
        "    response=llm.invoke(messages, temperature=temperature)\n",
        "    wrapped_response = wrap_text(response.content)\n",
        "    return wrapped_response"
      ],
      "id": "2035c541"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Movie Chain\n",
        "\n",
        "We will analyze an extended movie plot summary, identify the genre(s) of\n",
        "the film, generate a tagline, and then create a short synopsis\n",
        "incorporating the tagline and genres. The process involves the following\n",
        "steps:\n",
        "\n",
        "1.  **Initial Movie Plot**: The process starts with an extended movie\n",
        "    plot summary, which is provided as a string variable.\n",
        "\n",
        "2.  **Identify the Film Genre(s)**: The language model will identify the\n",
        "    primary genre(s) for the film based on the movie plot summary.\n",
        "\n",
        "3.  **Generate a Movie Tagline**: Based on the initial movie plot, a\n",
        "    catchy tagline for the movie is generated by prompting a language\n",
        "    model.\n",
        "\n",
        "4.  **Generate a Title**: Based on the initial movie plot and the movie\n",
        "    tagline generate a possible title.\n",
        "\n",
        "5.  **Generate a Short Synopsis**: Using the initial movie plot, the\n",
        "    generated tagline and title, and the identified genre(s), generate a\n",
        "    short synopsis for the movie.\n",
        "\n",
        "![Movie Chain\n",
        "Flow](https://calvinw.github.io/Ma322Notebooks/prompt-chain-graph.png)\n",
        "\n",
        "### Initial Movie Plot\n",
        "\n",
        "Let’s start with the extended movie plot summary:"
      ],
      "id": "719ef23c-500a-429c-aec2-05032189acb7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "movie_plot =\"\"\"\n",
        "In a post-apocalyptic world ravaged by a devastating cataclysm, a young woman\n",
        "named Tara sets out on a perilous journey to find a rumored sanctuary known as\n",
        "The Oasis – a legend that promises safety, resources, and a chance at\n",
        "rebuilding civilization.\n",
        "\n",
        "Tara's path is fraught with danger as she navigates the treacherous wastelands,\n",
        "where lawlessness and chaos reign supreme. Along the way, she encounters a\n",
        "ragtag group of survivors who have banded together for protection, forming an\n",
        "unlikely alliance born out of necessity.\n",
        "\n",
        "Despite initial mistrust and conflicting agendas, Tara and the survivors\n",
        "realize that their only hope of survival lies in cooperation. They must\n",
        "traverse a hostile landscape, facing off against ruthless marauders who will\n",
        "stop at nothing to claim what little resources remain, as well as mutated\n",
        "creatures twisted by the cataclysm's aftermath.\n",
        "\n",
        "As they uncover clues and follow a trail of breadcrumbs left by those who came\n",
        "before, the group is forced to confront not only the harsh realities of their\n",
        "new world but also their own inner demons and personal conflicts. They must\n",
        "make difficult choices that will test their morality, their loyalty, and their\n",
        "resolve, ultimately determining their fate and the fate of those who may follow\n",
        "in their footsteps.\n",
        "\n",
        "In this harrowing journey, the line between survival and sacrifice blurs, and\n",
        "the true cost of reaching The Oasis may be higher than any of them could have\n",
        "imagined.\n",
        "\"\"\""
      ],
      "id": "64f314e4"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Identify the Film Genre(s)\n",
        "\n",
        "Identify the primary genre(s) for the film based on the movie plot\n",
        "summary."
      ],
      "id": "4ad35fac-df25-4da2-992b-79d1329f7da8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "template =\"\"\"\n",
        "Based on the following movie plot summary, identify the primary genre(s) for\n",
        "the film. The plot is enclosed in <plot> </plot> tags:\n",
        "\n",
        "<plot>\n",
        "{plot}\n",
        "</plot>\n",
        "\n",
        "Provide your answer in a comma-separated list:\n",
        "\"\"\"\n",
        "\n",
        "prompt = template.format(plot=movie_plot)\n",
        "genre_response = get_completion(prompt)\n",
        "print(genre_response)"
      ],
      "id": "2deea94a"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Generate a Movie Tagline\n",
        "\n",
        "Generate a catchy tagline for the movie based on the initial movie plot."
      ],
      "id": "36623ab9-439e-4b8e-833e-0811d7b864ec"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "template =\"\"\"\n",
        "Based on the following movie plot, generate a catchy tagline for the movie.\n",
        "The plot is enclosed in <plot> </plot> tags:\n",
        "\n",
        "<plot>\n",
        "{plot}\n",
        "</plot>\n",
        "\"\"\"\n",
        "\n",
        "prompt = template.format(plot=movie_plot)\n",
        "tagline_response = get_completion(prompt)\n",
        "print(tagline_response)"
      ],
      "id": "7e94775f"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create a Title\n",
        "\n",
        "Based on the tagline and the plot summary, generate a title for the\n",
        "film."
      ],
      "id": "2fdd2a46-2c58-48da-9311-ee0c6cb9ea76"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "template =\"\"\"\n",
        "Based on the following movie plot summary and tagline generate a title for the\n",
        "movie. The plot is enclosed in <plot> </plot> tags and the tagline is enclosed\n",
        "in <tagline> </tagline> tags\n",
        "\n",
        "<plot>\n",
        "{plot}\n",
        "</plot>\n",
        "\n",
        "<tagline>\n",
        "{tagline}\n",
        "</tagline>\n",
        "\"\"\"\n",
        "\n",
        "prompt = template.format(plot=movie_plot,\n",
        "                         tagline=tagline_response)\n",
        "title_response = get_completion(prompt)\n",
        "print(title_response)"
      ],
      "id": "87358da9"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Generate a Short Synopsis\n",
        "\n",
        "Generate a short synopsis for the movie, incorporating the tagline and\n",
        "the identified genre(s)."
      ],
      "id": "38020750-0e2e-4c02-a342-2d49232b7643"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "template = \"\"\"\n",
        "Based on the following movie plot, tagline, title, and genres, generate a short\n",
        "synopsis for the movie of 50 words or less. The plot is contained in <plot>\n",
        "tags, the tagline is contained in <tagline> tags, the genres are contained\n",
        "<genres> tags, the title is contained in <title> tags. \n",
        "\n",
        "<plot>\n",
        "{plot}\n",
        "</plot>\n",
        "\n",
        "<genres> \n",
        "{genres}\n",
        "</genres> \n",
        "\n",
        "<tagline>\n",
        "{tagline}\n",
        "</tagline>\n",
        "\n",
        "<title>\n",
        "{title}\n",
        "</title>\n",
        "\"\"\"\n",
        "\n",
        "prompt = template.format(plot=movie_plot,\n",
        "                        tagline=tagline_response,\n",
        "                        genres=genre_response,\n",
        "                        title=title_response)\n",
        "synopsis_response = get_completion(prompt)\n",
        "print(synopsis_response)"
      ],
      "id": "9e05cf65"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Final Report for Movie Chain"
      ],
      "id": "761a5c9d-37a8-4398-b4b6-d07ac3dd7627"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "report_template = \"\"\"\n",
        "### Initial Movie Plot\n",
        "{plot}\n",
        "\n",
        "### Identified Genre(s)\n",
        "{genre}\n",
        "\n",
        "### Movie Tagline\n",
        "{tagline}\n",
        "\n",
        "### Movie Title\n",
        "{title}\n",
        "\n",
        "### Short Movie Synopsis\n",
        "{synopsis}\n",
        "\"\"\"\n",
        "\n",
        "report = report_template.format(plot = movie_plot,\n",
        "                         genre = genre_response,\n",
        "                         tagline = tagline_response,\n",
        "                         title = title_response,\n",
        "                         synopsis = synopsis_response)\n",
        "print(report)"
      ],
      "id": "f950525a"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    }
  }
}