{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# FString Chains\n",
        "\n",
        "### Put Your OPENROUTER_API_KEY here"
      ],
      "id": "c65f9b6a-a2c5-45b7-82c7-c980833276a3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"OPENROUTER_API_KEY\"] = \"paste_your_api_key_here\""
      ],
      "id": "3f170301"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip3 install langchain langchain_openai"
      ],
      "id": "e41b6e8e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "try:\n",
        "    model_name\n",
        "except NameError:\n",
        "    model_name=\"openai/gpt-4o-mini\"\n",
        "\n",
        "print(\"Model Name:\", model_name)\n",
        "print(\"Provider:\", \"OpenRouter AI\")\n",
        "\n",
        "llm=ChatOpenAI(model_name=model_name,\n",
        "               openai_api_key=os.environ.get(\"OPENROUTER_API_KEY\"),\n",
        "               openai_api_base=\"https://openrouter.ai/api/v1\")"
      ],
      "id": "a22f2bc7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import textwrap\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "def wrap_text(text, max_width=80):\n",
        "    \"\"\"\n",
        "    Wraps the text to the specified max_width, preserving line breaks and formatting.\n",
        "    \"\"\"\n",
        "    text = text.lstrip()\n",
        "    lines = text.splitlines()  # Split the text into lines\n",
        "    wrapped_lines = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Skip empty lines\n",
        "            wrapped_line = textwrap.fill(line, max_width, initial_indent='', subsequent_indent='')\n",
        "            wrapped_lines.extend(wrapped_line.splitlines())  # Preserve line breaks\n",
        "        else:\n",
        "            wrapped_lines.append('')  # Keep empty lines\n",
        "    return '\\n'.join(wrapped_lines)\n",
        "\n",
        "def print_prompt_and_response(prompt, response):\n",
        "    print(\"Prompt: \")\n",
        "    print(wrap_text(prompt))\n",
        "    print(\"\")\n",
        "    print(\"Response: \")\n",
        "    print(response)\n",
        "\n",
        "def print_messages_and_response(messages, response):\n",
        "    prompt = ChatPromptTemplate(messages=messages)\n",
        "    print_prompt_and_response(prompt.format(), response)\n",
        "\n",
        "def get_completion(prompt, temperature=0.0):\n",
        "    response = llm.invoke(prompt, temperature=temperature)\n",
        "    wrapped_response = wrap_text(response.content)\n",
        "    return wrapped_response\n",
        "\n",
        "def get_completion_messages(messages, temperature=0.0):\n",
        "    response=llm.invoke(messages, temperature=temperature)\n",
        "    wrapped_response = wrap_text(response.content)\n",
        "    return wrapped_response"
      ],
      "id": "5f0c5028"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here is an example of a simple chain with 2 calls to an LLM. The first\n",
        "call asks for 3 names of a company, then the second call asks the LLM to\n",
        "take the response from the first call and upper case it.\n",
        "\n",
        "This represents a chain of calls to LLMs and we want to show how to do\n",
        "this with F-strings.\n",
        "\n",
        "Its easy if we dont care about re-using the the chain. Here is how to\n",
        "achieve it with a couple of FStrings.\n",
        "\n",
        "Run the version below which is created with 2 F-strings. Each one is the\n",
        "prompt that will be passed to the LLM for that stage of the chain."
      ],
      "id": "dde0d559-ce42-434c-80d6-466b2e2ce1ba"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "thing = \"toothpicks\"\n",
        "\n",
        "first_query = f\"\"\"\n",
        "Give me 3 possible names for companies that make {thing}.\n",
        "Just list the 3 names like this:\n",
        "1 <Company 1 name>\n",
        "2 <Company 2 name>\n",
        "3 <Company 3 name>\n",
        "\"\"\"\n",
        "\n",
        "first_response = get_completion(first_query)\n",
        "print(first_response)\n",
        "\n",
        "second_query = f\"\"\"\n",
        "Can you upper case the text below:\n",
        "Just uppercase the text and return the uppercased version.\n",
        "\n",
        "{first_response}\n",
        "\n",
        "\"\"\"\n",
        "second_response = get_completion(second_query)\n",
        "print(second_response)"
      ],
      "id": "8ee365a4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def chain(thing):\n",
        "  first_query = f\"\"\"\n",
        "  Give me 3 possible names for companies that make {thing}.\n",
        "  Just list the 3 names like this:\n",
        "  1 <Company 1 name>\n",
        "  2 <Company 2 name>\n",
        "  3 <Company 3 name>\n",
        "  \"\"\"\n",
        "\n",
        "  first_response = get_completion(first_query)\n",
        "  print(first_response)\n",
        "  print(80*'-')\n",
        "\n",
        "  second_query = f\"\"\"\n",
        "  Can you upper case the text below:\n",
        "  Just uppercase the text and return the uppercased version.\n",
        "\n",
        "  {first_response}\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  second_response = get_completion(second_query)\n",
        "  return second_response\n",
        "\n",
        "response=chain(\"bikes\")\n",
        "print(response)\n",
        "\n",
        "print(80*\"*\")\n",
        "\n",
        "response=chain(\"firecrackers\")\n",
        "print(response)\n",
        "\n",
        "print(80*\"*\")\n",
        "\n",
        "response=chain(\"yoga mats\")\n",
        "print(response)"
      ],
      "id": "67d728c2"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    }
  }
}