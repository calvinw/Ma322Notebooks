{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Review Chain\n",
        "\n",
        "### Put Your OPENROUTER_API_KEY here"
      ],
      "id": "c72deb77-da63-4b08-a941-11b0584aad16"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"OPENROUTER_API_KEY\"] = \"paste_your_api_key_here\""
      ],
      "id": "fc8ef11f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip3 install langchain langchain_openai"
      ],
      "id": "0d4df740"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "try:\n",
        "    model_name\n",
        "except NameError:\n",
        "    model_name=\"openai/gpt-4o-mini\"\n",
        "\n",
        "print(\"Model Name:\", model_name)\n",
        "print(\"Provider:\", \"OpenRouter AI\")\n",
        "\n",
        "llm=ChatOpenAI(model_name=model_name,\n",
        "               openai_api_key=os.environ.get(\"OPENROUTER_API_KEY\"),\n",
        "               openai_api_base=\"https://openrouter.ai/api/v1\")"
      ],
      "id": "3993b9ed"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import textwrap\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "from IPython.display import display, clear_output, Markdown\n",
        "from ipywidgets import widgets, Layout\n",
        "\n",
        "conversation_output = widgets.Output()\n",
        "messages = []\n",
        "\n",
        "def run_chatbot(system_prompt, initial_message):\n",
        "    global messages \n",
        "    messages = [ {'role':'system', 'content': system_prompt} ]\n",
        "    conversation_output.clear_output()\n",
        "\n",
        "    messages.append({'role': 'assistant', 'content': initial_message})\n",
        "\n",
        "    text_input = widgets.Text(\n",
        "        placeholder='Type your message here...',\n",
        "        layout=widgets.Layout(width='50%')\n",
        "    )\n",
        "    submit_button = widgets.Button(description=\"Send\")\n",
        "\n",
        "    input_box = widgets.HBox([text_input, submit_button])\n",
        "    display(conversation_output, input_box)\n",
        "\n",
        "    def on_submit_click(b):\n",
        "        message = text_input.value\n",
        "        text_input.value = ''  # Clear the input field\n",
        "\n",
        "        with conversation_output:\n",
        "            display(Markdown(f\"**User**: {message}\"))\n",
        "            messages.append({'role': 'user', 'content': message})\n",
        "            response = get_completion_messages(messages)\n",
        "            display(Markdown(f\"**AI**: {response}\"))\n",
        "            messages.append({'role': 'assistant', 'content': response})\n",
        "\n",
        "    submit_button.on_click(on_submit_click)\n",
        "\n",
        "    # Display initial AI message\n",
        "    with conversation_output:\n",
        "        display(Markdown(f\"**AI**: {initial_message}\"))\n",
        "\n",
        "def wrap_text(text, max_width=80):\n",
        "    \"\"\"\n",
        "    Wraps the text to the specified max_width, preserving line breaks and formatting.\n",
        "    \"\"\"\n",
        "    text = text.lstrip()\n",
        "    lines = text.splitlines()  # Split the text into lines\n",
        "    wrapped_lines = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Skip empty lines\n",
        "            wrapped_line = textwrap.fill(line, max_width, initial_indent='', subsequent_indent='')\n",
        "            wrapped_lines.extend(wrapped_line.splitlines())  # Preserve line breaks\n",
        "        else:\n",
        "            wrapped_lines.append('')  # Keep empty lines\n",
        "    return '\\n'.join(wrapped_lines)\n",
        "\n",
        "def print_messages():\n",
        "    for message in messages:\n",
        "        role = message['role']\n",
        "        content = message['content']\n",
        "        \n",
        "        if role == 'system':\n",
        "            print(\"System:\")\n",
        "            print(\"-\" * 40)\n",
        "            print(content)\n",
        "        elif role == 'user':\n",
        "            print(\"User: \", end=\"\")\n",
        "            print(wrap_text(content))\n",
        "        elif role == 'assistant':\n",
        "            print(\"Assistant: \", end=\"\")\n",
        "            print(wrap_text(content))\n",
        "        print()  # Add an extra newline for spacing\n",
        "\n",
        "def print_prompt_and_response(prompt, response):\n",
        "    print(\"Prompt: \")\n",
        "    print(wrap_text(prompt))\n",
        "    print(\"\")\n",
        "    print(\"Response: \")\n",
        "    print(response)\n",
        "\n",
        "def print_messages_and_response(messages, response):\n",
        "    prompt = ChatPromptTemplate(messages=messages)\n",
        "    print_prompt_and_response(prompt.format(), response)\n",
        "\n",
        "def get_completion(prompt, temperature=0.0):\n",
        "    response = llm.invoke(prompt, temperature=temperature)\n",
        "    wrapped_response = wrap_text(response.content)\n",
        "    return wrapped_response\n",
        "\n",
        "def get_completion_messages(messages, temperature=0.0):\n",
        "    response=llm.invoke(messages, temperature=temperature)\n",
        "    wrapped_response = wrap_text(response.content)\n",
        "    return wrapped_response"
      ],
      "id": "ca253a43"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Review Chain\n",
        "\n",
        "We will analyze a customer review and summarize it. Then try to compose\n",
        "a response.\n",
        "\n",
        "Here are the steps in the analysis. Each of these will be a different\n",
        "call to the LLM. So we will call the LLM 4 times in this chain.\n",
        "\n",
        "1.  **Analyze the sentiment of the original review on a scale of 1 to\n",
        "    5**: The sentiment of the original review is analyzed on a scale of\n",
        "    1 (very negative) to 5 (very positive) by prompting a language\n",
        "    model.\n",
        "\n",
        "2.  **Categorize the Review Based On the Main Issue**: The main issue or\n",
        "    concern raised in the review is categorized into one of the\n",
        "    following categories: Product Quality, Shipping/Delivery, Customer\n",
        "    Service, Pricing, or Other.\n",
        "\n",
        "3.  **Suggest Potential Improvements Based On the Review**: At least\n",
        "    three potential improvements or changes are suggested to address the\n",
        "    customer’s concerns based on the review.\n",
        "\n",
        "4.  **Write an individualized email response to the customer**: A polite\n",
        "    and professional email response is drafted, addressing the\n",
        "    customer’s concerns.\n",
        "\n",
        "![Flow For Review\n",
        "Chain](https://calvinw.github.io/Ma322Notebooks/ReviewChainFlow1.png)\n",
        "\n",
        "We will use reviews from this page:\n",
        "\n",
        "[Brooks-Adrenaline-Womens-Supportive-Running](https://www.amazon.com/product-reviews/B08QVFHB8Y/ref=acr_dp_hist_1?ie=UTF8&filterByStar=one_star&reviewerType=all_reviews#reviews-filter-bar)\n",
        "\n",
        "We are going to use mostly negative reviews since we want compose an\n",
        "email to the customer about addressing their concerns.\n",
        "\n",
        "### Initial Review\n",
        "\n",
        "Lets start with the review text. We put them it the variable\n",
        "`current_review`"
      ],
      "id": "e5950990-9e4e-4da0-8716-ae16f87e92e8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "review = \"\"\"I don't know if you can tell from these pictures, but the\n",
        "top part of these shoes do not look like these are a matched pair. Moreover,\n",
        "the quality in the Brooks Adrenaline has plummeted over the years. The material\n",
        "on top is thinner and just cheaper feeling/looking overall. The fit is more\n",
        "narrow. The cushioning barely there, feels uneven throughout the foot bed,\n",
        "rather than smooth not to mention a poor attempt at arch support. The outside\n",
        "of the sole is misleading with the appearance that there will be more support\n",
        "in the arch and a cushioned feel overall, but that isn't the reality. The other\n",
        "thing I don't like is how the front part of running shoes is getting thinner.\n",
        "But that's pretty much every brand doing that in the name of creating a rocking\n",
        "wave. Maybe the science says, \"Yes, manufacturers, do this,\" but the painful\n",
        "balls of my feet and cramping toes say, \"Please stop doing this!\" And\n",
        "puhleez-the shoe laces are way too short. I barely, barely was able to get a\n",
        "small bow tied in the left shoe that looks navy. Maybe this was just a (highly)\n",
        "defective pair, but seriously, I have my doubts. I've been making do with my\n",
        "2019 version of Brooks Adrenaline because ever since then, the quality has been\n",
        "lacking. I was hoping for a better experience this time. Nope. If anything,\n",
        "this trial was the worst of them all. Looks like my days with Brooks are over.\n",
        "Time to find a better quality brand because these shoes are so not worth\n",
        "anywhere near the amount on the price tag listed. Disappointed! I hope you have\n",
        "a better experience. Please be sure to check who the seller is for the pair you\n",
        "want and what the return policy is just in case.\"\"\""
      ],
      "id": "996a510d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Analyze the Sentiment\n",
        "\n",
        "Create a prompt to ask the LLM to analyze our review for a rating score.\n",
        "\n",
        "-   Ask the LLM to analyze the review on a scale of 1(very negative) to\n",
        "    5(very positive)\n",
        "-   Instruct the LLM to return just the number 1 through 5\n",
        "-   Include a template variable called `{review}` so you can pass in a\n",
        "    review for this prompt.\n",
        "-   Template variables needed: `{review}`"
      ],
      "id": "38794cc7-d8a7-40a3-a3f1-7582de966854"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "template = \"\"\"\n",
        "\n",
        "<<REPLACE THIS AND PUT YOUR PROMPT TEMPLATE HERE>>\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "prompt = template.format(review=review)\n",
        "sentiment_response= get_completion(prompt)\n",
        "print(sentiment_response)"
      ],
      "id": "8796b58d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Categorize the Review\n",
        "\n",
        "Categorize the Review Based On the Main Issue\n",
        "\n",
        "-   Ask the LLM to categorize the main issue or concern raised in the\n",
        "    review\n",
        "-   Tell the LLM it should categorize it into the following categories:\n",
        "    Product Quality, Shipping/Delivery, Customer Service, Pricing,\n",
        "    Other.\n",
        "-   Ask it to just give the categories nothing more\n",
        "-   Template variables needed: `{review}`"
      ],
      "id": "abc8586e-ce25-433b-8433-8b5ee56a67bf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "template =\"\"\"\n",
        "\n",
        "<<REPLACE THIS AND PUT YOUR PROMPT TEMPLATE HERE>>\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "prompt = template.format(review=review)\n",
        "categorize_response = get_completion(prompt)\n",
        "print(categorize_response)"
      ],
      "id": "2124f355"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Suggest Potential Improvements\n",
        "\n",
        "Lets suggest 3 potential improvements\n",
        "\n",
        "-   Ask the LLM for three potential improvements or changes that could\n",
        "    address the customer’s concerns\n",
        "-   Template variables needed: `{review}`"
      ],
      "id": "9c102d47-35a7-413e-b7e0-ef19e7a58dcf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "template = \"\"\"\n",
        "\n",
        "<<REPLACE THIS AND PUT YOUR PROMPT TEMPLATE HERE>>\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "prompt = template.format(review=review)\n",
        "improvements_response = get_completion(prompt)\n",
        "print(improvements_response)"
      ],
      "id": "549c0b30"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Write an Individualized Response\n",
        "\n",
        "Write an individualized email response to the customer python\n",
        "\n",
        "-   Ask the LLM to write a brief but polite and professional email\n",
        "    response to the customer.\n",
        "-   Tell the LLM not to mention any return policy or refund\n",
        "-   Tell the LLM to mention that we are working on improvements\n",
        "-   Template variables needed: `{review}`, `{improvements}`"
      ],
      "id": "1a45261c-cfa1-4367-9e3e-96a45cf87c5e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "template = \"\"\"\n",
        "\n",
        "<<REPLACE THIS AND PUT YOUR PROMPT TEMPLATE HERE>>\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "prompt = template.format(review=review,\n",
        "                          improvements=improvements_response)\n",
        "email_response = get_completion(prompt)\n",
        "print(email_response)"
      ],
      "id": "85b58fe6"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Final Report for This Review"
      ],
      "id": "bad3d7ad-fcfa-40ea-b69f-f97ead6a1de4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "report_template = \"\"\"\n",
        "### Initial Review\n",
        "{review}\n",
        "\n",
        "### Sentiment 1 (very negative) to 5 (very positive)\n",
        "{sentiment}\n",
        "\n",
        "### Categorized Main Issue\n",
        "{categorize}\n",
        "\n",
        "### Potential Improvements\n",
        "{improvements}\n",
        "\n",
        "### Individualized Email Response\n",
        "{email}\n",
        "\"\"\"\n",
        "\n",
        "report = report_template.format(review=review,\n",
        "                                sentiment=sentiment_response,\n",
        "                                categorize=categorize_response,\n",
        "                                improvements=improvements_response,\n",
        "                                email=email_response)\n",
        "print(report)"
      ],
      "id": "c8470b89"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    }
  }
}