{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Simple Order Bot"
      ],
      "id": "971a99a5-ae29-436e-abb7-a854d658e24d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_name=\"openai/gpt-4o-mini\""
      ],
      "id": "1fdbe123"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Put Your OPENROUTER_API_KEY here"
      ],
      "id": "366bf16f-cbe7-4bbb-8210-9881890f722d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"OPENROUTER_API_KEY\"] = \"paste_your_api_key_here\""
      ],
      "id": "deeedda1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip3 install langchain langchain_openai"
      ],
      "id": "a054d1f8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "try:\n",
        "    model_name\n",
        "except NameError:\n",
        "    model_name=\"openai/gpt-4o-mini\"\n",
        "\n",
        "print(\"Model Name:\", model_name)\n",
        "print(\"Provider:\", \"OpenRouter AI\")\n",
        "\n",
        "llm=ChatOpenAI(model_name=model_name,\n",
        "               openai_api_key=os.environ.get(\"OPENROUTER_API_KEY\"),\n",
        "               openai_api_base=\"https://openrouter.ai/api/v1\")"
      ],
      "id": "78cca692"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import textwrap\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "from IPython.display import display, clear_output, Markdown\n",
        "from ipywidgets import widgets, Layout\n",
        "\n",
        "conversation_output = widgets.Output()\n",
        "messages = []\n",
        "\n",
        "def run_chatbot(system_prompt, initial_message):\n",
        "    global messages \n",
        "    messages = [ {'role':'system', 'content': system_prompt} ]\n",
        "    conversation_output.clear_output()\n",
        "\n",
        "    messages.append({'role': 'assistant', 'content': initial_message})\n",
        "\n",
        "    text_input = widgets.Text(\n",
        "        placeholder='Type your message here...',\n",
        "        layout=widgets.Layout(width='50%')\n",
        "    )\n",
        "    submit_button = widgets.Button(description=\"Send\")\n",
        "\n",
        "    input_box = widgets.HBox([text_input, submit_button])\n",
        "    display(conversation_output, input_box)\n",
        "\n",
        "    def on_submit_click(b):\n",
        "        message = text_input.value\n",
        "        text_input.value = ''  # Clear the input field\n",
        "\n",
        "        with conversation_output:\n",
        "            display(Markdown(f\"**User**: {message}\"))\n",
        "            messages.append({'role': 'user', 'content': message})\n",
        "            response = get_completion_messages(messages)\n",
        "            display(Markdown(f\"**AI**: {response}\"))\n",
        "            messages.append({'role': 'assistant', 'content': response})\n",
        "\n",
        "    submit_button.on_click(on_submit_click)\n",
        "\n",
        "    # Display initial AI message\n",
        "    with conversation_output:\n",
        "        display(Markdown(f\"**AI**: {initial_message}\"))\n",
        "\n",
        "def wrap_text(text, max_width=80):\n",
        "    \"\"\"\n",
        "    Wraps the text to the specified max_width, preserving line breaks and formatting.\n",
        "    \"\"\"\n",
        "    text = text.lstrip()\n",
        "    lines = text.splitlines()  # Split the text into lines\n",
        "    wrapped_lines = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Skip empty lines\n",
        "            wrapped_line = textwrap.fill(line, max_width, initial_indent='', subsequent_indent='')\n",
        "            wrapped_lines.extend(wrapped_line.splitlines())  # Preserve line breaks\n",
        "        else:\n",
        "            wrapped_lines.append('')  # Keep empty lines\n",
        "    return '\\n'.join(wrapped_lines)\n",
        "\n",
        "def print_messages():\n",
        "    for message in messages:\n",
        "        role = message['role']\n",
        "        content = message['content']\n",
        "        \n",
        "        if role == 'system':\n",
        "            print(\"System:\")\n",
        "            print(\"-\" * 40)\n",
        "            print(content)\n",
        "        elif role == 'user':\n",
        "            print(\"User: \", end=\"\")\n",
        "            print(wrap_text(content))\n",
        "        elif role == 'assistant':\n",
        "            print(\"Assistant: \", end=\"\")\n",
        "            print(wrap_text(content))\n",
        "        print()  # Add an extra newline for spacing\n",
        "\n",
        "def print_prompt_and_response(prompt, response):\n",
        "    print(\"Prompt: \")\n",
        "    print(wrap_text(prompt))\n",
        "    print(\"\")\n",
        "    print(\"Response: \")\n",
        "    print(response)\n",
        "\n",
        "def print_messages_and_response(messages, response):\n",
        "    prompt = ChatPromptTemplate(messages=messages)\n",
        "    print_prompt_and_response(prompt.format(), response)\n",
        "\n",
        "def get_completion(prompt, temperature=0.0):\n",
        "    response = llm.invoke(prompt, temperature=temperature)\n",
        "    wrapped_response = wrap_text(response.content)\n",
        "    return wrapped_response\n",
        "\n",
        "def get_completion_messages(messages, temperature=0.0):\n",
        "    response=llm.invoke(messages, temperature=temperature)\n",
        "    wrapped_response = wrap_text(response.content)\n",
        "    return wrapped_response"
      ],
      "id": "7063cf76"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Here we are building a simple bot to take pizza orders:\n",
        "\n",
        "Create an order bot, which is an automated service to collect orders for\n",
        "a pizza restaurant. Come up with a set of intructions for the\n",
        "`system_prompt` below.\n",
        "\n",
        "The following is the menu:\n",
        "\n",
        "Pizzas\n",
        "\n",
        "-   pepperoni pizza \\$12.95, \\$10.00, \\$7.00\n",
        "-   cheese pizza \\$10.95, \\$9.25, \\$6.50\n",
        "-   eggplant pizza \\$11.95, \\$9.75, \\$6.75\n",
        "\n",
        "Sides\n",
        "\n",
        "-   fries \\$4.50, \\$3.50\n",
        "-   greek salad \\$7.25\n",
        "\n",
        "Toppings\n",
        "\n",
        "-   extra cheese \\$2.00,\n",
        "-   mushrooms \\$1.50\n",
        "-   sausage \\$3.00\n",
        "-   canadian bacon \\$3.50\n",
        "-   peppers \\$1.00\n",
        "\n",
        "Drinks\n",
        "\n",
        "-   coke \\$3.00, \\$2.00, \\$1.00\n",
        "-   sprite \\$3.00, \\$2.00, \\$1.00\n",
        "-   bottled water \\$5.00\n",
        "\n",
        "Here are some things to implement. Try to implement and test each of\n",
        "these.\n",
        "\n",
        "## Requirements for the OrderBot\n",
        "\n",
        "1.  Greet the customer and introduce yourself as “Maggies Restaurant\n",
        "    Order Assistant”\n",
        "2.  Be able to display the entire menu or just a category depending on\n",
        "    the users requests\n",
        "3.  If the customer orders a item, ask them what size they want.\n",
        "4.  Confirm each item with the name of the item, the size and the price\n",
        "5.  Summarize the Order and give the prices and the total of all items.\n",
        "    Ask the customer if the order is correct.\n",
        "6.  Once the user is ready ask the user for their name and their phone\n",
        "    number.\n",
        "7.  Ask them if they will pickup or want delivery. If they want delivery\n",
        "    get an address."
      ],
      "id": "3cdbff5c-07ac-4ea9-8263-4aec70ceda41"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "system_prompt = \"\"\" You are a helpful assistant.\n",
        "\n",
        "<<< REPLACE WITH YOUR OWN DETAILS BUT LEAVE MENU BELOW>>>\n",
        "\n",
        "Below is the menu between the <menu> </menu> tags. It is in markdown. Please\n",
        "preserve the backslashes in front of the dollar signs when showing money\n",
        "amounts.\n",
        "\n",
        "<menu>\n",
        "Pizzas  \n",
        "\n",
        "- pepperoni pizza  \\$12.95, \\$10.00, \\$7.00\n",
        "- cheese pizza   \\$10.95, \\$9.25, \\$6.50\n",
        "- eggplant pizza   \\$11.95, \\$9.75, \\$6.75\n",
        "\n",
        "Sides\n",
        "\n",
        "- fries \\$4.50, \\$3.50\n",
        "- greek salad \\$7.25\n",
        "\n",
        "Toppings\n",
        "\n",
        "- extra cheese \\$2.00,\n",
        "- mushrooms \\$1.50\n",
        "- sausage \\$3.00\n",
        "- canadian bacon \\$3.50\n",
        "- peppers \\$1.00\n",
        "\n",
        "Drinks\n",
        "\n",
        "- coke \\$3.00, \\$2.00, \\$1.00\n",
        "- sprite \\$3.00, \\$2.00, \\$1.00\n",
        "- bottled water \\$5.00\n",
        "</menu>\n",
        "\"\"\"\n",
        "\n",
        "initial_message = \"Welcome ...\"\n",
        "run_chatbot(system_prompt, initial_message)"
      ],
      "id": "8f684bb7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print_messages()"
      ],
      "id": "86e0d0a5"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    }
  }
}