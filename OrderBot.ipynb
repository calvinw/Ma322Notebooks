{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Simple Order Bot"
      ],
      "id": "cfdc7f68-33dc-45c6-b53a-ac5cb88dd91d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_name=\"openai/gpt-4o-mini\""
      ],
      "id": "2b0c4e01"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Put Your OPENROUTER_API_KEY here"
      ],
      "id": "e27828a8-fbb5-4069-8b70-c4672e0b0fb2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"OPENROUTER_API_KEY\"] = \"paste_your_api_key_here\""
      ],
      "id": "86b7d983"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip3 install langchain langchain_openai"
      ],
      "id": "0fb1468c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "try:\n",
        "    model_name\n",
        "except NameError:\n",
        "    model_name=\"openai/gpt-4o-mini\"\n",
        "\n",
        "print(\"Model Name:\", model_name)\n",
        "print(\"Provider:\", \"OpenRouter AI\")\n",
        "\n",
        "llm=ChatOpenAI(model_name=model_name,\n",
        "               openai_api_key=os.environ.get(\"OPENROUTER_API_KEY\"),\n",
        "               openai_api_base=\"https://openrouter.ai/api/v1\")"
      ],
      "id": "73e2b2ed"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import textwrap\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "from IPython.display import display, clear_output, Markdown\n",
        "from ipywidgets import widgets, Layout\n",
        "\n",
        "conversation_output = widgets.Output()\n",
        "messages = []\n",
        "\n",
        "def run_chatbot(system_prompt, initial_message):\n",
        "    global messages \n",
        "    messages = [ {'role':'system', 'content': system_prompt} ]\n",
        "    conversation_output.clear_output()\n",
        "\n",
        "    messages.append({'role': 'assistant', 'content': initial_message})\n",
        "\n",
        "    text_input = widgets.Text(\n",
        "        placeholder='Type your message here...',\n",
        "        layout=widgets.Layout(width='50%')\n",
        "    )\n",
        "    submit_button = widgets.Button(description=\"Send\")\n",
        "\n",
        "    input_box = widgets.HBox([text_input, submit_button])\n",
        "    display(conversation_output, input_box)\n",
        "\n",
        "    def on_submit_click(b):\n",
        "        message = text_input.value\n",
        "        text_input.value = ''  # Clear the input field\n",
        "\n",
        "        with conversation_output:\n",
        "            display(Markdown(f\"**User**: {message}\"))\n",
        "            messages.append({'role': 'user', 'content': message})\n",
        "            response = get_completion_messages(messages)\n",
        "            display(Markdown(f\"**AI**: {response}\"))\n",
        "            messages.append({'role': 'assistant', 'content': response})\n",
        "\n",
        "    submit_button.on_click(on_submit_click)\n",
        "\n",
        "    # Display initial AI message\n",
        "    with conversation_output:\n",
        "        display(Markdown(f\"**AI**: {initial_message}\"))\n",
        "\n",
        "def wrap_text(text, max_width=80):\n",
        "    \"\"\"\n",
        "    Wraps the text to the specified max_width, preserving line breaks and formatting.\n",
        "    \"\"\"\n",
        "    text = text.lstrip()\n",
        "    lines = text.splitlines()  # Split the text into lines\n",
        "    wrapped_lines = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Skip empty lines\n",
        "            wrapped_line = textwrap.fill(line, max_width, initial_indent='', subsequent_indent='')\n",
        "            wrapped_lines.extend(wrapped_line.splitlines())  # Preserve line breaks\n",
        "        else:\n",
        "            wrapped_lines.append('')  # Keep empty lines\n",
        "    return '\\n'.join(wrapped_lines)\n",
        "\n",
        "def print_messages():\n",
        "    for message in messages:\n",
        "        role = message['role']\n",
        "        content = message['content']\n",
        "        \n",
        "        if role == 'system':\n",
        "            print(\"System:\")\n",
        "            print(\"-\" * 40)\n",
        "            print(content)\n",
        "        elif role == 'user':\n",
        "            print(\"User: \", end=\"\")\n",
        "            print(wrap_text(content))\n",
        "        elif role == 'assistant':\n",
        "            print(\"Assistant: \", end=\"\")\n",
        "            print(wrap_text(content))\n",
        "        print()  # Add an extra newline for spacing\n",
        "\n",
        "def print_prompt_and_response(prompt, response):\n",
        "    print(\"Prompt: \")\n",
        "    print(wrap_text(prompt))\n",
        "    print(\"\")\n",
        "    print(\"Response: \")\n",
        "    print(response)\n",
        "\n",
        "def print_messages_and_response(messages, response):\n",
        "    prompt = ChatPromptTemplate(messages=messages)\n",
        "    print_prompt_and_response(prompt.format(), response)\n",
        "\n",
        "def get_completion(prompt, temperature=0.0):\n",
        "    response = llm.invoke(prompt, temperature=temperature)\n",
        "    wrapped_response = wrap_text(response.content)\n",
        "    return wrapped_response\n",
        "\n",
        "def get_completion_messages(messages, temperature=0.0):\n",
        "    response=llm.invoke(messages, temperature=temperature)\n",
        "    wrapped_response = wrap_text(response.content)\n",
        "    return wrapped_response"
      ],
      "id": "f9243c1c"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Here we are building a simple bot to take pizza orders:\n",
        "\n",
        "Create an order bot, which is an automated service to collect orders for\n",
        "a pizza restaurant\n",
        "\n",
        "The bot should\n",
        "\n",
        "-   Greet the customer and collect the order\n",
        "-   Make sure to ask if itâ€™s for pickup or delivery\n",
        "-   Once the entire order is collected, summarize it and check for a\n",
        "    final time if the customer wants to add anything else\n",
        "-   If its a delivery order, ask for an address\n",
        "-   Collect the payment\n",
        "-   Clarify all options, extras and sizes to uniquely identify the item\n",
        "    from the menu\n",
        "-   Respond in a short, very conversational style\n",
        "\n",
        "The following is the menu:\n",
        "\n",
        "Pizzas\n",
        "\n",
        "-   pepperoni pizza 12.95, 10.00, 7.00\n",
        "-   cheese pizza 10.95, 9.25, 6.50\n",
        "-   eggplant pizza 11.95, 9.75, 6.75\n",
        "\n",
        "Sides\n",
        "\n",
        "-   fries 4.50, 3.50\n",
        "-   greek salad 7.25\n",
        "\n",
        "Toppings\n",
        "\n",
        "-   extra cheese 2.00,\n",
        "-   mushrooms 1.50\n",
        "-   sausage 3.00\n",
        "-   canadian bacon 3.50\n",
        "-   peppers 1.00\n",
        "\n",
        "Drinks\n",
        "\n",
        "-   coke 3.00, 2.00, 1.00\n",
        "-   sprite 3.00, 2.00, 1.00\n",
        "-   bottled water 5.00"
      ],
      "id": "94cecd72-3e66-4dbb-8d32-8dc802811019"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "system_prompt = \"\"\" You are a helpful assistant.\n",
        "<<< REPLACE WITH YOUR OWN DETAILS>>>\n",
        "\"\"\"\n",
        "\n",
        "initial_message = \"Welcome to our pizza restaurant. Can I take your order?\"\n",
        "run_chatbot(system_prompt, initial_message)"
      ],
      "id": "ec0db390"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print_messages()"
      ],
      "id": "7957e9f9"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    }
  }
}