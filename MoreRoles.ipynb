{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# More Roles\n",
        "\n",
        "## Put Your Together AI key here"
      ],
      "id": "181a1b64-df6f-458f-894d-7f41b147b775"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"TOGETHER_API_KEY\"] = \"paste_your_api_key_here\""
      ],
      "id": "9b63961b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Install Packages"
      ],
      "id": "ebddd7bc-4477-47e5-a3d1-309f51fb5770"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip3 install langchain langchain_openai"
      ],
      "id": "8cb9571a"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set up the LLM"
      ],
      "id": "8b2d62f8-05b5-411f-bc55-2077ae33a3b3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "#model_name = \"NousResearch/Nous-Hermes-2-Mixtral-8x7B-SFT\"\n",
        "#model_name = \"NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO\"\n",
        "#model_name=\"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
        "#model_name=\"mistralai/Mistral-7B-Instruct-v0.1\"\n",
        "#model_name=\"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "model_name = \"openchat/openchat-3.5-1210\"\n",
        "#model_name = \"Qwen/Qwen1.5-72B-Chat\"\n",
        "#model_name = \"cognitivecomputations/dolphin-2.5-mixtral-8x7b\"\n",
        "#model_name=\"databricks/dbrx-instruct\"\n",
        "#model_name=\"mistralai/Mixtral-8x22B\"\n",
        "#model_name=\"microsoft/WizardLM-2-8x22B\"\n",
        "\n",
        "print(\"Provider: TogetherAI\")\n",
        "print(\"Model: \" + model_name)\n",
        "\n",
        "llm=ChatOpenAI(model_name=model_name,\n",
        "               openai_api_key=os.environ.get(\"TOGETHER_API_KEY\"),\n",
        "               openai_api_base=\"https://api.together.xyz/v1/\")\n",
        "\n",
        "import textwrap\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "def wrap_text(text, max_width=80):\n",
        "    \"\"\"\n",
        "    Wraps the text to the specified max_width, preserving line breaks and formatting.\n",
        "    \"\"\"\n",
        "    text = text.lstrip()\n",
        "    lines = text.splitlines()  # Split the text into lines\n",
        "    wrapped_lines = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Skip empty lines\n",
        "            wrapped_line = textwrap.fill(line, max_width, initial_indent='', subsequent_indent='')\n",
        "            wrapped_lines.extend(wrapped_line.splitlines())  # Preserve line breaks\n",
        "        else:\n",
        "            wrapped_lines.append('')  # Keep empty lines\n",
        "    return '\\n'.join(wrapped_lines)\n",
        "\n",
        "def print_prompt_and_response(prompt, response):\n",
        "    print(\"Prompt: \")\n",
        "    print(wrap_text(prompt))\n",
        "    print(\"\")\n",
        "    print(\"Response: \")\n",
        "    print(response)\n",
        "\n",
        "def print_messages_and_response(messages, response):\n",
        "    prompt = ChatPromptTemplate(messages=messages)\n",
        "    print_prompt_and_response(prompt.format(), response)\n",
        "\n",
        "def get_completion(prompt, temperature=0.0):\n",
        "    response = llm.invoke(prompt, temperature=temperature)\n",
        "    wrapped_response = wrap_text(response.content)\n",
        "    return wrapped_response\n",
        "\n",
        "def get_completion_messages(messages, temperature=0.0):\n",
        "    response=llm.invoke(messages, temperature=temperature)\n",
        "    wrapped_response = wrap_text(response.content)\n",
        "    return wrapped_response\n"
      ],
      "id": "9d2262a4"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## What is a Black Hole?\n",
        "\n",
        "First like a physicist talking to their collegues\n",
        "\n",
        "-   Tell the LLM to adopt the role or persona of a physicist talking to\n",
        "    other physicists.\n",
        "-   Ask the LLM to explain the concept of a black hole"
      ],
      "id": "1066003d-8554-4115-aac2-be8ab250be65"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt = \"\"\"\n",
        "CODE\n",
        "\"\"\"\n",
        "response=get_completion(prompt)\n",
        "print(response)"
      ],
      "id": "14d6618d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now like a school teacher talking to some sixth grade students\n",
        "\n",
        "-   Tell the LLM to adopt the role of a teacher talking to sixth grade\n",
        "    students.\n",
        "-   Ask the LLM to explain the concept of a black hole"
      ],
      "id": "850e7e23-b596-4271-ba62-cc5c016120ee"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt = \"\"\"\n",
        "CODE\n",
        "\"\"\"\n",
        "response=get_completion(prompt)\n",
        "print(response)"
      ],
      "id": "8d6d4537"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## How many key strokes to type the numbers 1 to 500?\n",
        "\n",
        "So this is a problem where LLM has to realize how many digits are in the\n",
        "numbers as it tries to figure this out.\n",
        "\n",
        "-   1 through 9 are just one digit, so one keystroke for them\n",
        "-   10 through 99 are two digits, so two keystrokes for them\n",
        "-   100 through 500 are three digits, so three keystrokes for them\n",
        "\n",
        "There are 9 different numbers with 1 digit, 90 different numbers with 2\n",
        "digits, and 401 different numbers with 3 digits so:\n",
        "\n",
        "$$ 9(1) + 90(2) + 401(3) = 1392 $$\n",
        "\n",
        "Lets ask the LLM first without any role.\n",
        "\n",
        "-   Ask the LLM how many key strokes are needed to type the numbers from\n",
        "    1 to 500?"
      ],
      "id": "12ac76cf-01a8-4dfb-bbea-afa0a1754062"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt = \"\"\"\n",
        "CODE\n",
        "\"\"\"\n",
        "response=get_completion(prompt)\n",
        "print(response)"
      ],
      "id": "bf622edd"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   Ask the LLM how many key strokes are needed to type the numbers from\n",
        "    1 to 500\n",
        "-   Tell the LLM it should think step-by-step and that it is an expert\n",
        "    at counting things."
      ],
      "id": "e31ec9ce-922d-424e-bb0c-673a64001f00"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt = \"\"\"\n",
        "CODE\n",
        "\"\"\"\n",
        "response=get_completion(prompt)\n",
        "print(response)"
      ],
      "id": "3e056c02"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For this last one you might try various wordings, the LLM we are using\n",
        "currently seems to respond slightly differently depending on how you\n",
        "word things.\n",
        "\n",
        "You may not get it to get the exact answer but often the answer is much\n",
        "better than its initial attempt.\n",
        "\n",
        "The answer still has some inaccuracies. In one version of an answer the\n",
        "LLM claimed:\n",
        "\n",
        "> Numbers from 100 to 500 require three keystokes, (the first digit, the\n",
        "> second digit and the letter “h” for hundreds)\n",
        "\n",
        "What? The letter “h” is not something that you type for a number with 3\n",
        "digits. Not sure why it counted that."
      ],
      "id": "c7a557b5-a9e4-41e0-ae97-d9a40f03f0ed"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    }
  }
}