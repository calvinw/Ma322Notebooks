{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Roles\n",
        "\n",
        "## Set up your `TOGETHER_API_KEY`"
      ],
      "id": "d19ab0af-08be-4d8c-a447-a3cedc27c098"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "if os.environ.get(\"TOGETHER_API_KEY\") is None:\n",
        "   os.environ[\"TOGETHER_API_KEY\"] = \"paste_your_api_key_here\""
      ],
      "id": "0b60dddc"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Install Packages to Call the LLM\n",
        "\n",
        "For this part we set up the LLM."
      ],
      "id": "7a7277a0-45a7-44c0-b903-928598a2fd5f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip3 install openai"
      ],
      "id": "8112f325"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "import textwrap\n",
        "\n",
        "def wrap_text(text, max_width=80):\n",
        "    \"\"\"\n",
        "    Wraps the text to the specified max_width, preserving line breaks and formatting.\n",
        "    \"\"\"\n",
        "    lines = text.splitlines()  # Split the text into lines\n",
        "    wrapped_lines = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Skip empty lines\n",
        "            wrapped_line = textwrap.fill(line, max_width, initial_indent='', subsequent_indent='')\n",
        "            wrapped_lines.extend(wrapped_line.splitlines())  # Preserve line breaks\n",
        "        else:\n",
        "            wrapped_lines.append('')  # Keep empty lines\n",
        "    return '\\n'.join(wrapped_lines)\n",
        "\n",
        "def print_prompt_and_response(prompt, response):\n",
        "    print(\"Prompt: \")\n",
        "    print(prompt)\n",
        "    print(\"\")\n",
        "    print(\"Response: \")\n",
        "    print(response)\n",
        "\n",
        "def get_completion(prompt, temperature=0.0):\n",
        "    client = openai.OpenAI(api_key=os.environ.get(\"TOGETHER_API_KEY\"),\n",
        "                           base_url=\"https://api.together.xyz/v1\")\n",
        "    chat_completion = client.chat.completions.create(\n",
        "                           #model=\"NousResearch/Nous-Hermes-2-Mixtral-8x7B-SFT\",\n",
        "                           model=\"mistralai/Mistral-7B-Instruct-v0.1\",\n",
        "                           #model=\"zero-one-ai/Yi-34B-Chat\",\n",
        "                           #model=\"openchat/openchat-3.5-1210\",\n",
        "                           messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                           temperature=temperature,\n",
        "                           max_tokens=1024)\n",
        "    response = chat_completion.choices[0].message.content\n",
        "    response = response.lstrip()\n",
        "    wrapped_response = wrap_text(response)\n",
        "    return wrapped_response\n",
        "\n",
        "def get_completion_messages(messages, temperature=0.0):\n",
        "    client = openai.OpenAI(api_key=os.environ.get(\"TOGETHER_API_KEY\"),\n",
        "                           base_url=\"https://api.together.xyz/v1\")\n",
        "    chat_completion = client.chat.completions.create(\n",
        "                           #model=\"NousResearch/Nous-Hermes-2-Mixtral-8x7B-SFT\",\n",
        "                           #model=\"mistralai/Mistral-7B-Instruct-v0.1\",\n",
        "                           #model=\"zero-one-ai/Yi-34B-Chat\",\n",
        "                           model=\"openchat/openchat-3.5-1210\",\n",
        "                           messages=messages,\n",
        "                           temperature=temperature,\n",
        "                           max_tokens=1024)\n",
        "    response = chat_completion.choices[0].message.content\n",
        "    response = response.lstrip()\n",
        "    wrapped_response = wrap_text(response)\n",
        "    return wrapped_response"
      ],
      "id": "5624fc9d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## System and User Roles\n",
        "\n",
        "### System and User\n",
        "\n",
        "Here’s a simple system and user message:"
      ],
      "id": "3e4f91ae-5c3d-4e68-b10b-c1c60349ada6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "system_message =\"You are a cat.\"\n",
        "user_message = \"What do you think of skateboards?\"\n",
        "\n",
        "messages =  [\n",
        "  {'role':'system','content': system_message},\n",
        "  {'role':'user','content': user_message},\n",
        "]\n",
        "\n",
        "response = get_completion_messages(messages)\n",
        "print(messages[0]['role'])\n",
        "print(messages[0]['content'])\n",
        "\n",
        "print(messages[1]['role'])\n",
        "print(messages[1]['content'])\n",
        "print(\"\")\n",
        "print(\"Response\")\n",
        "print(response)"
      ],
      "id": "7197cb89"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "system_message =\"You are a kid.\"\n",
        "user_message = \"What do you think of skateboards?\"\n",
        "\n",
        "messages =  [\n",
        "  {'role':'system','content': system_message},\n",
        "  {'role':'user','content': user_message},\n",
        "]\n",
        "\n",
        "response = get_completion_messages(messages)\n",
        "print(messages[0]['role'])\n",
        "print(messages[0]['content'])\n",
        "\n",
        "print(messages[1]['role'])\n",
        "print(messages[1]['content'])\n",
        "print(\"\")\n",
        "print(\"Response\")\n",
        "print(response)"
      ],
      "id": "08529192"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "system_message =\"\"\"\n",
        "\"\"\"\n",
        "user_message = \"\"\"\n",
        "Jack is looking at Anne. Anne is looking at George. Jack is married, George is not, and we don’t know if Anne is married. Is a married person looking at an unmarried person?\n",
        "\"\"\"\n",
        "\n",
        "messages =  [\n",
        "  {'role':'system','content': system_message},\n",
        "  {'role':'user','content': user_message},\n",
        "]\n",
        "\n",
        "response = get_completion_messages(messages)\n",
        "print(messages[0]['role'])\n",
        "print(messages[0]['content'])\n",
        "\n",
        "print(messages[1]['role'])\n",
        "print(messages[1]['content'])\n",
        "print(\"\")\n",
        "print(\"Response\")\n",
        "print(response)"
      ],
      "id": "12259250"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "system_message =\"\"\"\n",
        "You are a smart professor of logic who can answer complex logic problems. Think through all the possibilities before you answer.\n",
        "\"\"\"\n",
        "user_message = \"\"\"\n",
        "Jack is looking at Anne. Anne is looking at George. Jack is married, George is not, and we don’t know if Anne is married. Is a married person looking at an unmarried person?\n",
        "\"\"\"\n",
        "\n",
        "messages =  [\n",
        "  {'role':'system','content': system_message},\n",
        "  {'role':'user','content': user_message},\n",
        "]\n",
        "\n",
        "response = get_completion_messages(messages)\n",
        "print(messages[0]['role'])\n",
        "print(messages[0]['content'])\n",
        "\n",
        "print(messages[1]['role'])\n",
        "print(messages[1]['content'])\n",
        "print(\"\")\n",
        "print(\"Response\")\n",
        "print(response)"
      ],
      "id": "c38e0dd1"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    }
  }
}