{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Roles"
      ],
      "id": "d1267ca9-e810-472a-b704-9415a0a1be78"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "if os.environ.get(\"TOGETHER_API_KEY\") is None:\n",
        "   os.environ[\"TOGETHER_API_KEY\"] = \"paste_your_api_key_here\""
      ],
      "id": "f1904c86"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip3 install langchain langchain_openai"
      ],
      "id": "a7233f89"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "model_name = \"NousResearch/Nous-Hermes-2-Mixtral-8x7B-SFT\"\n",
        "#model_name = \"NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO\"\n",
        "#model_name=\"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
        "#model_name=\"mistralai/Mistral-7B-Instruct-v0.1\"\n",
        "#model_name=\"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "#model_name = \"openchat/openchat-3.5-1210\"\n",
        "#model_name = \"Qwen/Qwen1.5-72B-Chat\"\n",
        "\n",
        "print(\"Provider: TogetherAI\")\n",
        "print(\"Model: \" + model_name)\n",
        "\n",
        "llm=ChatOpenAI(model_name=model_name,\n",
        "               openai_api_key=os.environ.get(\"TOGETHER_API_KEY\"),\n",
        "               openai_api_base=\"https://api.together.xyz/v1/\")"
      ],
      "id": "f9ab889e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import textwrap\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "def wrap_text(text, max_width=80):\n",
        "    \"\"\"\n",
        "    Wraps the text to the specified max_width, preserving line breaks and formatting.\n",
        "    \"\"\"\n",
        "    text = text.lstrip()\n",
        "    lines = text.splitlines()  # Split the text into lines\n",
        "    wrapped_lines = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Skip empty lines\n",
        "            wrapped_line = textwrap.fill(line, max_width, initial_indent='', subsequent_indent='')\n",
        "            wrapped_lines.extend(wrapped_line.splitlines())  # Preserve line breaks\n",
        "        else:\n",
        "            wrapped_lines.append('')  # Keep empty lines\n",
        "    return '\\n'.join(wrapped_lines)\n",
        "\n",
        "def print_prompt_and_response(prompt, response):\n",
        "    print(\"Prompt: \")\n",
        "    print(wrap_text(prompt))\n",
        "    print(\"\")\n",
        "    print(\"Response: \")\n",
        "    print(response)\n",
        "\n",
        "def print_messages_and_response(messages, response):\n",
        "    prompt = ChatPromptTemplate(messages=messages)\n",
        "    print_prompt_and_response(prompt.format(), response)\n",
        "\n",
        "def get_completion(prompt, temperature=0.0):\n",
        "    response = llm.invoke(prompt, temperature=temperature)\n",
        "    wrapped_response = wrap_text(response.content)\n",
        "    return wrapped_response\n",
        "\n",
        "def get_completion_messages(messages, temperature=0.0):\n",
        "    response=llm.invoke(messages, temperature=temperature)\n",
        "    wrapped_response = wrap_text(response.content)\n",
        "    return wrapped_response"
      ],
      "id": "361a7e0c"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Act Like a Cat\n",
        "\n",
        "We can tell the LLM in a `System` message that it is to act like a cat."
      ],
      "id": "82c023f6-a8df-46f2-a89a-1900648f178f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "system_message = \"You are a cat\"\n",
        "user_message = \"What do you think of skateboards?\"\n",
        "\n",
        "prompt=f\"\"\"{system_message}\n",
        "{user_message}\n",
        "\"\"\"\n",
        "response=get_completion(prompt)\n",
        "print_prompt_and_response(prompt, response)"
      ],
      "id": "dbfbac70"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Act Like a Kid"
      ],
      "id": "dc2d886d-a175-485d-bfcc-af315f2125ba"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "system_message = \"You are a kid\"\n",
        "user_message = \"What do you think of skateboards?\"\n",
        "\n",
        "prompt=f\"\"\"{system_message}\n",
        "{user_message}\n",
        "\"\"\"\n",
        "response=get_completion(prompt)\n",
        "print_prompt_and_response(prompt, response)"
      ],
      "id": "02b96562"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Is a Married Person Looking at an Unmarried Person?\n",
        "\n",
        "In this part we ask the LLM to solve a logical problem. We just try to\n",
        "have it solve the problem without any additional prompting."
      ],
      "id": "182c4c3f-13e3-4c4b-909a-dfddf9f86c8c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "system_message = \"\"\n",
        "user_message = \"\"\"\n",
        "Jack is looking at Anne. Anne is looking at George. Jack is married, George is\n",
        "not, and we don’t know if Anne is married. Is a married person looking at an\n",
        "unmarried person?\n",
        "\"\"\"\n",
        "\n",
        "prompt=f\"\"\"{system_message}\n",
        "{user_message}\n",
        "\"\"\"\n",
        "\n",
        "response=get_completion(prompt)\n",
        "print_prompt_and_response(prompt, response)"
      ],
      "id": "d55f9996"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Act Like a Professor of Logic\n",
        "\n",
        "But now we tell the LLM its a professor of logic and it should think\n",
        "through all the possibilities. With many LLMs this gets them closer to\n",
        "the right solution and sometimes they get it completly right with this\n",
        "kind of prompting.\n",
        "\n",
        "Asking a model to think “step-by-step” or by listing its reasoning is\n",
        "called “Chain of Thought(CoT)” prompting."
      ],
      "id": "ea49fe91-505b-4eb8-a167-e863d3211a88"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "system_message= \"\"\"You are a smart professor of logic who can answer complex\n",
        "logic problems. Think through all the possibilities before you answer.\"\"\"\n",
        "\n",
        "user_message = \"\"\"Jack is looking at Anne. Anne is looking at George. Jack is\n",
        "married, George is not, and we don’t know if Anne is married. Is a married\n",
        "person looking at an unmarried person?\n",
        "\"\"\"\n",
        "\n",
        "prompt=f\"\"\"{system_message}\n",
        "{user_message}\n",
        "\"\"\"\n",
        "\n",
        "response=get_completion(prompt)\n",
        "print_prompt_and_response(prompt, response)"
      ],
      "id": "ee7c43a3"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Is This Equation Solved Correctly?\n",
        "\n",
        "Without further prompting we ask the LLM if this (incorrect) problem\n",
        "solution is correct."
      ],
      "id": "04817163-401e-48a4-90a6-52abd0c5f989"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "system_message = \"\"\n",
        "user_message = \"\"\"\n",
        "Is this equation solved correctly below?\n",
        "\n",
        "2x-3=9\n",
        "2x=6\n",
        "x=3\n",
        "\"\"\"\n",
        "\n",
        "prompt=f\"\"\"{system_message}\n",
        "{user_message}\n",
        "\"\"\"\n",
        "\n",
        "response=get_completion(prompt)\n",
        "print_prompt_and_response(prompt, response)"
      ],
      "id": "3a727803"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## You are a Teacher of Math. Reason Step-By-Step\n",
        "\n",
        "Now we ask it again, but this time we tell it that its a teacher of\n",
        "math."
      ],
      "id": "666366e5-2924-4fed-9b56-72dfa380e285"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "system_message =\"\"\"\n",
        "You are a teacher of math. And can reason step-by-step to see if something is correct. First work out your own solution to the problem. Then compare your solution to the given solution.\n",
        "\"\"\"\n",
        "user_message = \"\"\"\n",
        "Is this problem solved correctly below?\n",
        "2x-3=9\n",
        "2x=6\n",
        "x=3\n",
        "\"\"\"\n",
        "\n",
        "prompt=f\"\"\"{system_message}\n",
        "{user_message}\n",
        "\"\"\"\n",
        "\n",
        "response=get_completion(prompt)\n",
        "print_prompt_and_response(prompt, response)"
      ],
      "id": "6edcc51d"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    }
  }
}