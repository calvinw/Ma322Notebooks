{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# More LLMS\n",
        "\n",
        "## Set up your `OPENAI_API_KEY`"
      ],
      "id": "9e9e7ffb-69a9-46f5-a8de-4ac546231410"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "if os.environ.get(\"OPENAI_API_KEY\") is None:\n",
        "   os.environ[\"OPENAI_API_KEY\"] = \"paste your api key here\""
      ],
      "id": "017bf164"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Install Packages to Call the LLM\n",
        "\n",
        "For this part we set up the LLM."
      ],
      "id": "03c637f7-636e-426e-bd59-a02097ddd8ad"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip3 install openai"
      ],
      "id": "cedb0a33"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import openai\n",
        "import textwrap\n",
        "\n",
        "def wrap_text(text, max_width=80):\n",
        "    \"\"\"\n",
        "    Wraps the text to the specified max_width, preserving line breaks and formatting.\n",
        "    \"\"\"\n",
        "    lines = text.splitlines()  # Split the text into lines\n",
        "    wrapped_lines = []\n",
        "\n",
        "    for line in lines:\n",
        "        if line.strip():  # Skip empty lines\n",
        "            wrapped_line = textwrap.fill(line, max_width, initial_indent='', subsequent_indent='')\n",
        "            wrapped_lines.extend(wrapped_line.splitlines())  # Preserve line breaks\n",
        "        else:\n",
        "            wrapped_lines.append('')  # Keep empty lines\n",
        "\n",
        "    return '\\n'.join(wrapped_lines)\n",
        "\n",
        "\n",
        "def print_prompt_and_response(prompt, response):\n",
        "    print(\"Prompt: \")\n",
        "    print(prompt)\n",
        "    print(\"\")\n",
        "    print(\"Response: \")\n",
        "    print(response)\n",
        "    print(80*\"=\")\n",
        "\n",
        "def get_completion(prompt, temperature=0.0):\n",
        "    # Create the OpenAI LLM\n",
        "    client = openai.OpenAI()\n",
        "    chat_completion = client.chat.completions.create(\n",
        "                           model=\"gpt-3.5-turbo\",\n",
        "                           messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                           temperature=temperature,\n",
        "                           max_tokens=1024)\n",
        "\n",
        "    response = chat_completion.choices[0].message.content\n",
        "    wrapped_response = wrap_text(response)\n",
        "    return wrapped_response"
      ],
      "id": "43c2e194"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Calling an LLM\n",
        "\n",
        "-   Choose a question and set up the code to send the question to the\n",
        "    LLM. Any question you like."
      ],
      "id": "cc0c9a42-8663-4ddc-9df2-6f6fd32ca18c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define your prompt here\n",
        "CODE\n",
        "\n",
        "# Call get_completion and get the response, then print it.\n",
        "CODE"
      ],
      "id": "f160d238"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Calling an LLM with `temperature=0.0`\n",
        "\n",
        "Call the LLM 3 times with your question above, using temperature 0.0 for\n",
        "these.\n",
        "\n",
        "-   Call `get_completion` and store the response. Then print it.\n",
        "-   You already defined `prompt` above so you do not need to repeat\n",
        "    that.\n",
        "-   Set `temperature=0.0`"
      ],
      "id": "a1c5f534-066d-440d-ae72-4ad403778dea"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CODE"
      ],
      "id": "38547f66"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   Exactly the same as above."
      ],
      "id": "ff8f8f1f-309f-407f-98fc-98ed21720b91"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CODE"
      ],
      "id": "78a24005"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   Exactly the same as above."
      ],
      "id": "ff2df63e-250b-49b5-92f3-311a20780e6e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CODE"
      ],
      "id": "8e79c8f6"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Calling an LLM with `temperature=0.7`\n",
        "\n",
        "Call the LLM 3 times with your question above, using temperature 0.7 for\n",
        "these.\n",
        "\n",
        "-   Call `get_completion` and store the response. Then print it.\n",
        "-   You already defined `prompt` above so you do not need to repeat\n",
        "    that.\n",
        "-   Set `temperature=0.7`"
      ],
      "id": "b929471a-91d3-4717-96e9-caaabf715b61"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CODE"
      ],
      "id": "a825d612"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   Exactly the same as above."
      ],
      "id": "376f17c1-040b-4550-8b94-6491b6222a77"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CODE"
      ],
      "id": "5c1385e6"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   Exactly the same as above."
      ],
      "id": "10433c16-811e-49d3-94f0-c81f84d38730"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CODE"
      ],
      "id": "daac4e17"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Template For Asking For a Capital\n",
        "\n",
        "Fill in the appropriate sections of the code below where you see the\n",
        "word CODE.\n",
        "\n",
        "-   Create a template string with a template variable `place` for asking\n",
        "    the LLM to give you the capital of `place`. Then evaulate the\n",
        "    template variable using `place=\"Texas\"`\n",
        "-   Finally call the LLM and get the response and print the response."
      ],
      "id": "338888dc-856d-4223-96e4-e0cab8ea0473"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define template here\n",
        "CODE\n",
        "\n",
        "# Evaluate the template with place=\"Texas\"\n",
        "prompt=template.format(CODE)\n",
        "\n",
        "# Call get_completion and get the response, then print it.\n",
        "CODE"
      ],
      "id": "ef8349ea"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Adding a Variable Called `num`\n",
        "\n",
        "-   Add another template variable called `num` to the template and ask\n",
        "    the LLM to provide you with `num` facts about the capital that you\n",
        "    specified with `place`.\n",
        "-   Call your template with `num=3` so you get 3 facts about the\n",
        "    capital."
      ],
      "id": "481f7c3d-2ad7-4577-9a1a-b9dbe7da9f3b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define template here\n",
        "CODE\n",
        "\n",
        "# Evaluate the template for \"Texas\" and 3 facts\n",
        "prompt=template.format(CODE)\n",
        "\n",
        "# Call get_completion and get the response, then print it.\n",
        "CODE"
      ],
      "id": "280e0a7d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ask To Format the Response\n",
        "\n",
        "-   Add a template variable called `format` so you can pass in the\n",
        "    desired format for the facts that are given.\n",
        "-   Call your template with “Texas” and 3 facts and “uppercase” for the\n",
        "    format"
      ],
      "id": "f3967a7e-a998-4c7d-aeae-689c053568b5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define template here\n",
        "CODE\n",
        "\n",
        "# Evaluate the template for \"Texas\" and 3 facts and \"uppercase\"\n",
        "prompt=template.format(CODE)\n",
        "\n",
        "# Call get_completion and get the response, then print it.\n",
        "CODE"
      ],
      "id": "b9bd74f5"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sending Several Requests to the LLM about Capitals\n",
        "\n",
        "Let’s see how this looks if we ask for the capital of several places.\n",
        "\n",
        "Replace CODE below to\n",
        "\n",
        "-   Create a template, then create a list called `myPlaces` of places to\n",
        "    use. Use Missouri, Florida, Germany and use 3 facts about the\n",
        "    capitals and use “a bullet point list” for the format.\n",
        "-   In the for loop call `get_completion` and then\n",
        "    `print_prompt_and_completion`"
      ],
      "id": "a4d66d26-4c68-4bcd-a599-ddbf00c4fe9d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define template here\n",
        "CODE\n",
        "\n",
        "# Create the list of places.\n",
        "myPlaces = CODE\n",
        "\n",
        "# Loop through the myPlaces\n",
        "for item in myPlaces:\n",
        "  prompt = template.format(CODE)\n",
        "  # Call get_completion, then print_prompt_and_response\n",
        "  CODE"
      ],
      "id": "2858fe14"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    }
  }
}
