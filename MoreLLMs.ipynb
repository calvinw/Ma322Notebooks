{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# More LLMS\n",
        "\n",
        "## Set up your `TOGETHER_API_KEY`"
      ],
      "id": "563baa3a-8e93-4a46-86e7-feae0af97e93"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "if os.environ.get(\"TOGETHER_API_KEY\") is None:\n",
        "   os.environ[\"TOGETHER_API_KEY\"] = \"paste_your_api_key_here\""
      ],
      "id": "0dac6ec2"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Install Packages to Call the LLM\n",
        "\n",
        "For this part we set up the LLM."
      ],
      "id": "a5586e50-caa2-4964-9726-b947cdd39b00"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip3 install openai"
      ],
      "id": "ac1d7fe8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import openai\n",
        "import textwrap\n",
        "\n",
        "def wrap_text(text, max_width=80):\n",
        "    \"\"\"\n",
        "    Wraps the text to the specified max_width, preserving line breaks and formatting.\n",
        "    \"\"\"\n",
        "    lines = text.splitlines()  # Split the text into lines\n",
        "    wrapped_lines = []\n",
        "\n",
        "    for line in lines:\n",
        "        if line.strip():  # Skip empty lines\n",
        "            wrapped_line = textwrap.fill(line, max_width, initial_indent='', subsequent_indent='')\n",
        "            wrapped_lines.extend(wrapped_line.splitlines())  # Preserve line breaks\n",
        "        else:\n",
        "            wrapped_lines.append('')  # Keep empty lines\n",
        "\n",
        "    return '\\n'.join(wrapped_lines)\n",
        "\n",
        "\n",
        "def print_prompt_and_response(prompt, response):\n",
        "    print(\"Prompt: \")\n",
        "    print(prompt)\n",
        "    print(\"\")\n",
        "    print(\"Response: \")\n",
        "    print(response)\n",
        "\n",
        "def get_completion(prompt, temperature=0.0):\n",
        "    client = openai.OpenAI(api_key=os.environ.get(\"TOGETHER_API_KEY\"),\n",
        "                           base_url=\"https://api.together.xyz/v1\")\n",
        "\n",
        "    chat_completion = client.chat.completions.create(\n",
        "                           model=\"NousResearch/Nous-Hermes-2-Mixtral-8x7B-SFT\",\n",
        "                           messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                           temperature=temperature,\n",
        "                           max_tokens=1024)\n",
        "\n",
        "    response = chat_completion.choices[0].message.content\n",
        "    response = response.lstrip()\n",
        "    wrapped_response = wrap_text(response)\n",
        "    return wrapped_response"
      ],
      "id": "b1caa619"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Calling an LLM\n",
        "\n",
        "-   Choose a question and set up a prompt to send the question to the\n",
        "    LLM. Any question you like."
      ],
      "id": "81e293a8-0890-417c-85a0-3c574fbd1141"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt = CODE"
      ],
      "id": "dc25975a"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   Run the cell below to print out your response"
      ],
      "id": "3d78e923-dff9-4abf-8e79-7832de75639c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "id": "c45467dc"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   Run the cell below to print out your prompt and your response\n",
        "    together"
      ],
      "id": "ab606eef-7aae-4c10-9576-f08b4a192e4b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "response = get_completion(prompt)\n",
        "print_prompt_and_response(prompt,response)"
      ],
      "id": "4072270f"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Calling an LLM with `temperature=0.0`\n",
        "\n",
        "Call the LLM 3 times with your question above, using temperature 0.0 for\n",
        "these.\n",
        "\n",
        "-   Using the same prompt as above call `get_completion` three times\n",
        "    with `temperature=0`\n",
        "-   Each time print out the response you get"
      ],
      "id": "ae88e29a-6502-4593-b09b-f47bfa15c56b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CODE"
      ],
      "id": "ac84236f"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   Exactly the same as above but use `temperature=0.7` instead"
      ],
      "id": "2f0c892f-9444-48ae-b9c0-46bb96a9e13a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CODE"
      ],
      "id": "3a9d9ec0"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Template For Asking For a Capital\n",
        "\n",
        "-   Create a template string with using a template variable `{place}`\n",
        "    for asking the LLM to give you the capital of `{place}`."
      ],
      "id": "3019bb91-b2f8-4b97-b0e1-af7e16740eae"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "template = CODE"
      ],
      "id": "cd7444cf"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   Evaluate your template with `place=\"Texas\"`\n",
        "-   Call `get_completion` to get the response from the LLM\n",
        "-   print the response using `print_prompt_and_response`"
      ],
      "id": "e79ea6a2-7e6e-40a0-8bbe-c1cfccc1cb1b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt=template.format(CODE)\n",
        "\n",
        "# Call the LLM by passing the prompt to get_completion\n",
        "response=get_completion(CODE)\n",
        "\n",
        "# Print the response\n",
        "print_prompt_and_response(prompt,response)"
      ],
      "id": "ed5e65e1"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Adding a Variable Called `num`\n",
        "\n",
        "-   Add another template variable called `{num}` to the template and ask\n",
        "    the LLM to provide you with `num` facts about the capital that you\n",
        "    specified with `{place}`."
      ],
      "id": "720f1666-278b-4843-a0d3-812bae2d7824"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "template = CODE"
      ],
      "id": "a7510003"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   Evaluate your template with `place=\"Texas\"` and `num=3` and save it\n",
        "    in the `prompt` variable"
      ],
      "id": "da1f330d-627a-42a3-84de-6c8dce8e4389"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt=template.format(CODE)"
      ],
      "id": "75ead1b6"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   Now call `get_completion` with the prompt and get the response.\n",
        "    Store it in the `response` variable"
      ],
      "id": "c6855029-53e5-4b11-ae1e-2fbd1e3cdfb6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "response = get_completion(CODE)"
      ],
      "id": "72dd945f"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   Use `print_prompt_and_response` to print out the prompt and\n",
        "    completion."
      ],
      "id": "27e72c1d-60e5-4994-82ca-228b9181401d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CODE"
      ],
      "id": "bbe9d4d4"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ask To Format the Response\n",
        "\n",
        "-   Add a template variable called `format` so you can pass in the\n",
        "    desired format for the facts that are given.\n",
        "-   Call your template with “Texas” and 3 facts and “uppercase” for the\n",
        "    format"
      ],
      "id": "33b97cee-0987-43d5-97e3-9e873c4dd880"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define template here\n",
        "template = CODE\n",
        "\n",
        "# Evaluate the template using place=\"Texas\" and num=3 and format=\"upper case\"\n",
        "prompt=template.format(CODE)\n",
        "\n",
        "# Call get_completion and get the response, then print it.\n",
        "response = get_completion(prompt)\n",
        "print_prompt_and_response(prompt,response)"
      ],
      "id": "8923d033"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    }
  }
}