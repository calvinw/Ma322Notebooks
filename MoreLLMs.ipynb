{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# More LLMS\n",
        "\n",
        "## Set up your `TOGETHER_API_KEY`"
      ],
      "id": "dfe94772-a209-4244-b642-a6425a36310f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "if os.environ.get(\"TOGETHER_API_KEY\") is None:\n",
        "   os.environ[\"TOGETHER_API_KEY\"] = \"paste_your_api_key_here\""
      ],
      "id": "63ce6637"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Install Packages to Call the LLM\n",
        "\n",
        "For this part we set up the LLM."
      ],
      "id": "efc8d28e-fc49-414e-b124-89d5af7e52c8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip3 install openai"
      ],
      "id": "ee11927d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import openai\n",
        "import textwrap\n",
        "\n",
        "def wrap_text(text, max_width=80):\n",
        "    \"\"\"\n",
        "    Wraps the text to the specified max_width, preserving line breaks and formatting.\n",
        "    \"\"\"\n",
        "    lines = text.splitlines()  # Split the text into lines\n",
        "    wrapped_lines = []\n",
        "\n",
        "    for line in lines:\n",
        "        if line.strip():  # Skip empty lines\n",
        "            wrapped_line = textwrap.fill(line, max_width, initial_indent='', subsequent_indent='')\n",
        "            wrapped_lines.extend(wrapped_line.splitlines())  # Preserve line breaks\n",
        "        else:\n",
        "            wrapped_lines.append('')  # Keep empty lines\n",
        "\n",
        "    return '\\n'.join(wrapped_lines)\n",
        "\n",
        "\n",
        "def print_prompt_and_response(prompt, response):\n",
        "    print(\"Prompt: \")\n",
        "    print(prompt)\n",
        "    print(\"\")\n",
        "    print(\"Response: \")\n",
        "    print(response)\n",
        "\n",
        "def get_completion(prompt, temperature=0.0):\n",
        "    client = openai.OpenAI(api_key=os.environ.get(\"TOGETHER_API_KEY\"),\n",
        "                           base_url=\"https://api.together.xyz/v1\")\n",
        "\n",
        "    chat_completion = client.chat.completions.create(\n",
        "                           model=\"NousResearch/Nous-Hermes-2-Mixtral-8x7B-SFT\",\n",
        "                           messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                           temperature=temperature,\n",
        "                           max_tokens=1024)\n",
        "\n",
        "    response = chat_completion.choices[0].message.content\n",
        "    response = response.lstrip()\n",
        "    wrapped_response = wrap_text(response)\n",
        "    return wrapped_response"
      ],
      "id": "10acd5c8"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Calling an LLM\n",
        "\n",
        "-   Choose a question and set up a prompt to send the question to the\n",
        "    LLM. Any question you like."
      ],
      "id": "6cd44617-951b-4d5e-afd0-fb91f9c427c7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt = CODE"
      ],
      "id": "907056ea"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   Run the cell below to print out your response"
      ],
      "id": "167d6468-d14f-4186-aabc-480a445978fe"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "id": "a78cdfe1"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   Run the cell below to print out your prompt and your response\n",
        "    together"
      ],
      "id": "afd936d3-9028-48b0-9aec-7fb539597e46"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "response = get_completion(prompt)\n",
        "print_prompt_and_response(prompt,response)"
      ],
      "id": "cec44c3e"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Calling an LLM with `temperature=0.0`\n",
        "\n",
        "Call the LLM 3 times with your question above, using temperature 0.0 for\n",
        "these.\n",
        "\n",
        "-   Using the same prompt as above call `get_completion` three times\n",
        "    with `temperature=0`\n",
        "-   Each time print out the response you get"
      ],
      "id": "c781bcb9-fc6f-40ad-add9-0e6be00ea797"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CODE"
      ],
      "id": "f345944a"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   Exactly the same as above but use `temperature=0.7` instead"
      ],
      "id": "5faada6e-b5d7-4148-82cb-515859034593"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CODE"
      ],
      "id": "b56ee61d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Template For Asking For a Capital\n",
        "\n",
        "-   Create a template string with using a template variable `{place}`\n",
        "    for asking the LLM to give you the capital of `{place}`."
      ],
      "id": "9ad9aeb0-2444-4690-b524-26dd917e00c1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "template = CODE"
      ],
      "id": "0d5b6999"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   Evaluate your template with `place=\"Texas\"`\n",
        "-   Call `get_completion` to get the response from the LLM\n",
        "-   print the response using `print_prompt_and_response`"
      ],
      "id": "ea7e802d-2fb9-4d22-9530-a86d59a8c977"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt=template.format(CODE)\n",
        "\n",
        "# Call the LLM by passing the prompt to get_completion\n",
        "response=get_completion(CODE)\n",
        "\n",
        "# Print the response\n",
        "print_prompt_and_response(prompt,response)"
      ],
      "id": "7e830b03"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Adding a Variable Called `num`\n",
        "\n",
        "-   Add another template variable called `{num}` to the template and ask\n",
        "    the LLM to provide you with `num` facts about the capital that you\n",
        "    specified with `{place}`."
      ],
      "id": "149bca2e-185d-417c-8889-9045b0f3869f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "template = CODE"
      ],
      "id": "8b95083b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   Evaluate your template with `place=\"Texas\"` and `num=3` and save it\n",
        "    in the `prompt` variable"
      ],
      "id": "419de0bc-d0e3-4909-bedd-f2c0dc6d7823"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt=template.format(CODE)"
      ],
      "id": "3393af6a"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   Now call `get_completion` with the prompt and get the response.\n",
        "    Store it in the `response` variable"
      ],
      "id": "ae271eaa-4e68-44fa-9cbf-8a94d4e40c00"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "response = get_completion(CODE)"
      ],
      "id": "19f8b275"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   Use `print_prompt_and_response` to print out the prompt and\n",
        "    completion."
      ],
      "id": "c05fdf2c-7467-4ec0-b52a-dc2ebfb3ae31"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CODE"
      ],
      "id": "87359c09"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ask To Format the Response\n",
        "\n",
        "-   Add a template variable called `format` so you can pass in the\n",
        "    desired format for the facts that are given.\n",
        "-   Call your template with “Texas” and 3 facts and “uppercase” for the\n",
        "    format"
      ],
      "id": "4b1c4855-1404-425e-ab10-1cec32654bb0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define template here\n",
        "template = CODE\n",
        "\n",
        "# Evaluate the template using place=\"Texas\" and num=3 and format=\"upper case\"\n",
        "prompt=template.format(CODE)\n",
        "\n",
        "# Call get_completion and get the response, then print it.\n",
        "response = get_completion(prompt)\n",
        "print_prompt_and_response(prompt,response)"
      ],
      "id": "a15ea18c"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    }
  }
}