{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# More LLMS\n",
        "\n",
        "## Set up your `TOGETHER_API_KEY`"
      ],
      "id": "1ed05a6b-c49a-4eb5-9a6c-138f5f6b193d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "if os.environ.get(\"TOGETHER_API_KEY\") is None:\n",
        "   os.environ[\"TOGETHER_API_KEY\"] = \"paste_your_api_key_here\""
      ],
      "id": "6e80658d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Install Packages to Call the LLM\n",
        "\n",
        "For this part we set up the LLM."
      ],
      "id": "9e7f19a9-641d-46fa-a2d2-f42a2def0e81"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip3 install openai"
      ],
      "id": "22e450d0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "import textwrap\n",
        "\n",
        "def wrap_text(text, max_width=80):\n",
        "    \"\"\"\n",
        "    Wraps the text to the specified max_width, preserving line breaks and formatting.\n",
        "    \"\"\"\n",
        "    lines = text.splitlines()  # Split the text into lines\n",
        "    wrapped_lines = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Skip empty lines\n",
        "            wrapped_line = textwrap.fill(line, max_width, initial_indent='', subsequent_indent='')\n",
        "            wrapped_lines.extend(wrapped_line.splitlines())  # Preserve line breaks\n",
        "        else:\n",
        "            wrapped_lines.append('')  # Keep empty lines\n",
        "    return '\\n'.join(wrapped_lines)\n",
        "\n",
        "def print_prompt_and_response(prompt, response):\n",
        "    print(\"Prompt: \")\n",
        "    print(prompt)\n",
        "    print(\"\")\n",
        "    print(\"Response: \")\n",
        "    print(response)\n",
        "\n",
        "def get_completion(prompt, temperature=0.0):\n",
        "    client = openai.OpenAI(api_key=os.environ.get(\"TOGETHER_API_KEY\"),\n",
        "                           base_url=\"https://api.together.xyz/v1\")\n",
        "    chat_completion = client.chat.completions.create(\n",
        "                           model=\"NousResearch/Nous-Hermes-2-Mixtral-8x7B-SFT\",\n",
        "                           #model=\"zero-one-ai/Yi-34B-Chat\",\n",
        "                           #model=\"openchat/openchat-3.5-1210\",\n",
        "                           messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                           temperature=temperature,\n",
        "                           max_tokens=1024)\n",
        "    response = chat_completion.choices[0].message.content\n",
        "    response = response.lstrip()\n",
        "    wrapped_response = wrap_text(response)\n",
        "    return wrapped_response"
      ],
      "id": "f4d6e131"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Calling an LLM\n",
        "\n",
        "-   Choose a question and set up a prompt to send the question to the\n",
        "    LLM. Any question you like."
      ],
      "id": "d7d9a3ca-2d4a-444d-b89b-eed231d67b62"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt = CODE"
      ],
      "id": "189ed0f2"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   Run the cell below to print out your response"
      ],
      "id": "deb81c24-21d9-4443-87f4-d4c2f492e62d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "id": "2d57d3c3"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   Run the cell below to print out your prompt and your response\n",
        "    together"
      ],
      "id": "012753bf-8be3-43b2-8255-5251e6934530"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "response = get_completion(prompt)\n",
        "print_prompt_and_response(prompt,response)"
      ],
      "id": "5d412812"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Calling an LLM with `temperature=0.0`\n",
        "\n",
        "Call the LLM 3 times with your question above, using temperature 0.0 for\n",
        "these.\n",
        "\n",
        "-   Using the same prompt as above call `get_completion` three times\n",
        "    with `temperature=0`\n",
        "-   Each time print out the response you get"
      ],
      "id": "d8fdc6e0-adfd-4d99-8368-01cc4487263c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CODE"
      ],
      "id": "43aa07b7"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   Exactly the same as above but use `temperature=0.7` instead"
      ],
      "id": "4131116f-6773-48f9-84c9-2539311c0c6f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CODE"
      ],
      "id": "8336a9b9"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Template For Asking For a Capital\n",
        "\n",
        "-   Create a template string with using a template variable `{place}`\n",
        "    for asking the LLM to give you the capital of `{place}`."
      ],
      "id": "b5cb101f-6ef4-4743-afda-cc06eaeb8a9d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "template = CODE"
      ],
      "id": "132658e4"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   Evaluate your template with `place=\"Texas\"`\n",
        "-   Call `get_completion` to get the response from the LLM\n",
        "-   print the response using `print_prompt_and_response`"
      ],
      "id": "03f5850c-4e48-439c-90d2-56ae1fe3e5b9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt=template.format(CODE)\n",
        "\n",
        "# Call the LLM by passing the prompt to get_completion\n",
        "response=get_completion(CODE)\n",
        "\n",
        "# Print the response\n",
        "print_prompt_and_response(prompt,response)"
      ],
      "id": "34038b04"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Adding a Variable Called `num`\n",
        "\n",
        "-   Add another template variable called `{num}` to the template and ask\n",
        "    the LLM to provide you with `num` facts about the capital that you\n",
        "    specified with `{place}`."
      ],
      "id": "729f55f4-92c9-4345-af8b-281f7fd543ca"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "template = CODE"
      ],
      "id": "8cad04f0"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   Evaluate your template with `place=\"Texas\"` and `num=3` and save it\n",
        "    in the `prompt` variable"
      ],
      "id": "bb0803c6-0dd5-43e9-8262-cdb76908a2cc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt=template.format(CODE)"
      ],
      "id": "0b977465"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   Now call `get_completion` with the prompt and get the response.\n",
        "    Store it in the `response` variable"
      ],
      "id": "7a3d09cc-5717-4387-baa6-511b124363a6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "response = get_completion(CODE)"
      ],
      "id": "6ef69f40"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   Use `print_prompt_and_response` to print out the prompt and\n",
        "    completion."
      ],
      "id": "9c6749f9-6733-4714-939b-46c74ebb57ed"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CODE"
      ],
      "id": "f254ee66"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ask To Format the Response\n",
        "\n",
        "-   Add a template variable called `format` so you can pass in the\n",
        "    desired format for the facts that are given.\n",
        "-   Call your template with “Texas” and 3 facts and “uppercase” for the\n",
        "    format"
      ],
      "id": "468effcc-b98c-49a0-94a0-a4b6d9622e76"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define template here\n",
        "template = CODE\n",
        "\n",
        "# Evaluate the template using place=\"Texas\" and num=3 and format=\"upper case\"\n",
        "prompt=template.format(CODE)\n",
        "\n",
        "# Call get_completion and get the response, then print it.\n",
        "response = get_completion(prompt)\n",
        "print_prompt_and_response(prompt,response)"
      ],
      "id": "4d9306a8"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    }
  }
}