{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LLMS\n",
        "\n",
        "## Set up your `TOGETHER_API_KEY`"
      ],
      "id": "75b81148-fe40-4feb-8852-b8c0949b1531"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "if os.environ.get(\"TOGETHER_API_KEY\") is None:\n",
        "   os.environ[\"TOGETHER_API_KEY\"] = \"paste_your_api_key_here\""
      ],
      "id": "951788c2"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Install Packages to Call the LLM\n",
        "\n",
        "For this part we set up the LLM."
      ],
      "id": "fc81f080-7c7f-4e62-9664-db258898407e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip3 install openai"
      ],
      "id": "329d9f8c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import openai\n",
        "import textwrap\n",
        "\n",
        "def wrap_text(text, max_width=80):\n",
        "    \"\"\"\n",
        "    Wraps the text to the specified max_width, preserving line breaks and formatting.\n",
        "    \"\"\"\n",
        "    lines = text.splitlines()  # Split the text into lines\n",
        "    wrapped_lines = []\n",
        "\n",
        "    for line in lines:\n",
        "        if line.strip():  # Skip empty lines\n",
        "            wrapped_line = textwrap.fill(line, max_width, initial_indent='', subsequent_indent='')\n",
        "            wrapped_lines.extend(wrapped_line.splitlines())  # Preserve line breaks\n",
        "        else:\n",
        "            wrapped_lines.append('')  # Keep empty lines\n",
        "\n",
        "    return '\\n'.join(wrapped_lines)\n",
        "\n",
        "\n",
        "def print_prompt_and_response(prompt, response):\n",
        "    print(\"Prompt: \")\n",
        "    print(prompt)\n",
        "    print(\"\")\n",
        "    print(\"Response: \")\n",
        "    print(response)\n",
        "\n",
        "def get_completion(prompt, temperature=0.0):\n",
        "    client = openai.OpenAI(api_key=os.environ.get(\"TOGETHER_API_KEY\"),\n",
        "                           base_url=\"https://api.together.xyz/v1\")\n",
        "\n",
        "    chat_completion = client.chat.completions.create(\n",
        "                           model=\"NousResearch/Nous-Hermes-2-Mixtral-8x7B-SFT\",\n",
        "                           #model=\"zero-one-ai/Yi-34B-Chat\",\n",
        "                           messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                           temperature=temperature,\n",
        "                           max_tokens=1024)\n",
        "\n",
        "    response = chat_completion.choices[0].message.content\n",
        "    response = response.lstrip()\n",
        "    wrapped_response = wrap_text(response)\n",
        "    return wrapped_response"
      ],
      "id": "74b63ddd"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Calling an LLM with `get_completion`\n",
        "\n",
        "First set up a prompt we can use:"
      ],
      "id": "833f655e-a046-4002-b351-77dd02e67fdf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt = \"Why is the sky blue? In 50 words or less.\""
      ],
      "id": "3d4dcdb6"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we call the`get_completion` function. This function takes our prompt\n",
        "as argument and sends it off to the LLM. The LLM returns a response.\n",
        "This function returns that response."
      ],
      "id": "ff5e0696-6dcf-4ed7-9f54-63c21a82c070"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "id": "8aabf2f6"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Sometimes its nice to print out the prompt and the response when we are\n",
        "working like this. We can use the function `print_prompt_and_response`\n",
        "and pass it the prompt and the response we got from the `get_completion`\n",
        "function."
      ],
      "id": "9899ab4c-0c96-4a6a-bd2e-05cb7f7fc279"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "response = get_completion(prompt)\n",
        "print_prompt_and_response(prompt, response)"
      ],
      "id": "91b11b1b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Calling an LLM with the `temperature`\n",
        "\n",
        "Temperature is one of the settings that most LLMs have. You can set the\n",
        "temperature from 0.0 up to some maximum (like 1.0 or 1.2). Sometimes you\n",
        "can go higher.\n",
        "\n",
        "Roughly\n",
        "\n",
        "1.  Low temperature (eg 0.2-0.5)\n",
        "    -   Generates more predictable and conservative text\n",
        "2.  Medium temperature (eg. 0.6-0.8)\n",
        "    -   Balances between creativity and coherence\n",
        "3.  High temperature (eg. 0.9-1.2)\n",
        "    -   Generates more creative diverse, and unpredictable text\n",
        "\n",
        "First lets set up a prompt to call several times with different\n",
        "temperatures."
      ],
      "id": "29302bb7-c760-4cfe-8b9a-cc8fef6e1553"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt = \"Why is the sky blue? In 50 words or less\""
      ],
      "id": "13a72e5b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Calling with `temperature=0.0`\n",
        "\n",
        "`temperature` is parameter you can pass to the `get_completion`\n",
        "function. You see this in the code below.\n",
        "\n",
        "Here we call the LLM 3 times with temperature 0.0"
      ],
      "id": "44a486fa-0ee6-45f0-bbc8-a4d5b7327a2b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "response = get_completion(prompt, temperature = 0.0)\n",
        "print(response)\n",
        "print(\"------\")\n",
        "\n",
        "response = get_completion(prompt, temperature = 0.0)\n",
        "print(response)\n",
        "print(\"------\")\n",
        "\n",
        "response = get_completion(prompt, temperature = 0.0)\n",
        "print(response)\n",
        "print(\"------\")"
      ],
      "id": "68ebe208"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Calling with `temperature=0.4`\n",
        "\n",
        "Here we call the LLM 3 times with temperature 0.4"
      ],
      "id": "2f255880-ba2f-4a48-b9bc-6cc623a87b1f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "response = get_completion(prompt, temperature = 0.4)\n",
        "print(response)\n",
        "print(\"------\")\n",
        "\n",
        "response = get_completion(prompt, temperature = 0.4)\n",
        "print(response)\n",
        "print(\"------\")\n",
        "\n",
        "response = get_completion(prompt, temperature = 0.4)\n",
        "print(response)\n",
        "print(\"------\")"
      ],
      "id": "76cf4f7b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Calling with `temperature=1.0`"
      ],
      "id": "9895e762-044e-40d8-9b60-fe03b9a8e692"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "response = get_completion(prompt, temperature = 1.0)\n",
        "print(response)\n",
        "print(\"------\")\n",
        "\n",
        "response = get_completion(prompt, temperature = 1.0)\n",
        "print(response)\n",
        "print(\"------\")\n",
        "\n",
        "response = get_completion(prompt, temperature = 1.0)\n",
        "print(response)\n",
        "print(\"------\")"
      ],
      "id": "2d286576"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Calling the LLM using a template\n",
        "\n",
        "Remember the template for having the LLM give us the name of a company\n",
        "that makes a particular thing?"
      ],
      "id": "af9b0d1c-1af5-4e5f-b76f-dddfc6882137"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "template = \"Recommend a name for a company that makes {what}\""
      ],
      "id": "91c7017b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets set that up and call it with `what=\"cars\"`:"
      ],
      "id": "93ff9090-6f73-4b9d-8122-51f91e83477a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt=template.format(what=\"cars\")\n",
        "response = get_completion(prompt)\n",
        "print_prompt_and_response(prompt, response)"
      ],
      "id": "92390034"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Change the template variable `{what}`\n",
        "\n",
        "Let’s call the LLM using `what=\"books\"` as the template variable."
      ],
      "id": "bb0017e1-4de1-4ee3-906c-1bd471dc79c6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt=template.format(what=\"books\")\n",
        "response = get_completion(prompt)\n",
        "print_prompt_and_response(prompt, response)"
      ],
      "id": "d7a6df43"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Add A Template Variable `{num}`"
      ],
      "id": "85c6a79b-bda1-4fe2-871d-39705dc4f457"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "template = \"Recommend {num} names for a company that makes {what}\""
      ],
      "id": "1a737076"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets call it with `num=3` and `what=\"cars\"`:"
      ],
      "id": "b4cb9fc2-bb97-469e-ba37-cef8a5316c05"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt=template.format(num=3, what=\"cars\")\n",
        "response = get_completion(prompt)\n",
        "print_prompt_and_response(prompt, response)"
      ],
      "id": "97a47353"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Add a Template Variable `{format}`\n",
        "\n",
        "Lets see if we can introduce some formatting to the output:"
      ],
      "id": "335ea4e2-ac53-4722-a562-6eb4048a08f1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "template =\"\"\"Recommend {num} names for a company that makes {what}.\n",
        "Give your answer in {format}\"\"\""
      ],
      "id": "10897ecc"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Call the LLM:"
      ],
      "id": "ce26ec9e-279c-4163-a25c-d1c159b93edd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt=template.format(num=3, what=\"cars\", format=\"A bulleted list using upper case\")\n",
        "response = get_completion(prompt)\n",
        "print_prompt_and_response(prompt, response)"
      ],
      "id": "c3c129fa"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Using a template to analyze reviews\n",
        "\n",
        "Finally in this example, we use a template for asking the LLM to analyze\n",
        "some reviews of a product.\n",
        "\n",
        "This shows how the template idea works. We can work on the template\n",
        "separately from the reviews in just one place, that way once the\n",
        "template works we can apply it to any number of reviews.\n",
        "\n",
        "Here are the reviews:"
      ],
      "id": "faf69f97-46cf-4210-81c7-f487ec629e11"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "first_review = \"\"\"So close! Aside from the technical issues — I ordered a small\n",
        "of the less busy face pattern, and received a medium in the more busy face\n",
        "pattern option instead. I’m 5’6” 135-140lbs. The sizes were European. This\n",
        "medium was a little big but still would have felt cute, if not for the collar\n",
        "and neckline. The collar has a high backing that doesn’t allow it to fall too\n",
        "well around your neck, and since the fabric is very thin and one-sided, you can\n",
        "see the back of the pattern when the collar is open (see photos). While okay\n",
        "for casual wear, and has a great boxy cut, the exposed back of fabric feels a\n",
        "bit cheap. Shirt is a good length for tucking in and a bit long otherwise.\"\"\"\n",
        "\n",
        "second_review = \"\"\"I love the pattern on this shirt, and I wanted to keep it so\n",
        "badly!! A few issues, though, made me send it back. 1 - The shirt looks much\n",
        "shinier/glossier on the models, and it's not. It's not shiny at all. It's a\n",
        "very nice fabric that is lightweight, but it hangs a lot differently that what\n",
        "was shown. 2 - The front is very short. The back hangs down nicely, but if you\n",
        "want to hide any tummy issues, this shirt won't do it for you. I also felt like\n",
        "my arms couldn't come up any or the shirt would be too high. I do a lot of\n",
        "presenting so this was a no go for me. 3 - The stitching on the front pulls\n",
        "oddly, so although it was big enough to button across the chest area, the\n",
        "stitching made it seem as though it was pulling even when it wasn't. Could just\n",
        "be my experience, but I don't like looking like the shirt is barely holding on,\n",
        "ha. I am 5'4 with a more muscular build (wide shoulders too) so that might be\n",
        "part of it. I love this shirt and wish it would work for me, but the shortness\n",
        "of it and the way it pulls made it a no-go.\"\"\""
      ],
      "id": "4244ab24"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And here is our template."
      ],
      "id": "486a61cb-abe2-4cb7-b72c-36d74b2f74fa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Here is our template\n",
        "template=\"\"\"\n",
        "You will be given a review in <text> tags below.\n",
        "\n",
        "- Summarize the review using around {length} words\n",
        "- On a separate line give {num} keywords that identify the main concerns in the review\n",
        "\n",
        "<text>\n",
        "{review}\n",
        "</text>\n",
        "\"\"\""
      ],
      "id": "d1ebd909"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets pass in the first review."
      ],
      "id": "6daff8fc-7f5f-4e5b-8e69-23c00e7412ca"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt=template.format(review=second_review, num=3, length=100)\n",
        "response = get_completion(prompt)\n",
        "print_prompt_and_response(prompt, response)"
      ],
      "id": "8dd2c5c2"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets pass in the second review."
      ],
      "id": "8b04eee8-a6b7-437d-83bc-390e11948a29"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt=template.format(review=second_review, num=5, length=50)\n",
        "response = get_completion(prompt)\n",
        "print_prompt_and_response(prompt, response)"
      ],
      "id": "ba88629f"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    }
  }
}