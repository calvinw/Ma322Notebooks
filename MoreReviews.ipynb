{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# More Analyzing Reviews with LLMs\n",
        "\n",
        "## Set up your `TOGETHER_API_KEY`"
      ],
      "id": "620b422a-ef10-45f6-8dc0-5e72501d2bec"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "if os.environ.get(\"TOGETHER_API_KEY\") is None:\n",
        "   os.environ[\"TOGETHER_API_KEY\"] = \"paste_your_api_key_here\""
      ],
      "id": "a8330f09"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup to Call the LLM\n",
        "\n",
        "For this part, we install the required package to interact with a\n",
        "TogetherAI language model."
      ],
      "id": "30e0a5f5-0cda-4904-b2b3-a6c43aae9b5f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip3 install langchain langchain_openai"
      ],
      "id": "03ae0d52"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain_openai import ChatOpenAI\n",
        "from IPython.display import Markdown\n",
        "\n",
        "model_name = \"NousResearch/Nous-Hermes-2-Mixtral-8x7B-SFT\"\n",
        "#model_name = \"NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO\"\n",
        "#model_name=\"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
        "#model_name=\"mistralai/Mistral-7B-Instruct-v0.1\"\n",
        "#model_name=\"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "#model_name = \"openchat/openchat-3.5-1210\"\n",
        "#model_name = \"Qwen/Qwen1.5-72B-Chat\"\n",
        "\n",
        "display(Markdown(\"### Model:  \\n#### \" + model_name))\n",
        "\n",
        "llm=ChatOpenAI(model_name=model_name,\n",
        "               openai_api_key=os.environ.get(\"TOGETHER_API_KEY\"),\n",
        "               openai_api_base=\"https://api.together.xyz/v1/\")"
      ],
      "id": "534dd060"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import textwrap\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "def wrap_text(text, max_width=80):\n",
        "    \"\"\"\n",
        "    Wraps the text to the specified max_width, preserving line breaks and formatting.\n",
        "    \"\"\"\n",
        "    lines = text.splitlines()  # Split the text into lines\n",
        "    wrapped_lines = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Skip empty lines\n",
        "            wrapped_line = textwrap.fill(line, max_width, initial_indent='', subsequent_indent='')\n",
        "            wrapped_lines.extend(wrapped_line.splitlines())  # Preserve line breaks\n",
        "        else:\n",
        "            wrapped_lines.append('')  # Keep empty lines\n",
        "    return '\\n'.join(wrapped_lines)\n",
        "\n",
        "def print_prompt_and_response(prompt, response):\n",
        "    print(\"Prompt: \")\n",
        "    print(wrap_text(prompt))\n",
        "    print(\"\")\n",
        "    print(\"Response: \")\n",
        "    print(response)\n",
        "\n",
        "def print_messages_and_response(messages, response):\n",
        "    prompt = ChatPromptTemplate(messages=messages)\n",
        "    print_prompt_and_response(prompt.format(), response)\n",
        "\n",
        "def get_completion(prompt, temperature=0.0):\n",
        "    response = llm.invoke(prompt, temperature=temperature)\n",
        "    wrapped_response = wrap_text(response.content)\n",
        "    return wrapped_response\n",
        "\n",
        "def get_completion_messages(messages, temperature=0.0):\n",
        "    response=llm.invoke(messages, temperature=temperature)\n",
        "    wrapped_response = wrap_text(response.content)\n",
        "    return wrapped_response"
      ],
      "id": "4bc1a71c"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analyzing Amazon Reviews\n",
        "\n",
        "Lets summarize a few reviews from this product:\n",
        "\n",
        "[Hanes Women’s Slub Knit Full-Zip Hoodie, Textured Cotton Zip-Up T-Shirt\n",
        "Hoodie for\n",
        "Women](https://www.amazon.com/product-reviews/B016YKIF60/ref=cm_cr_arp_d_viewopt_srt?ie=UTF8&filterByStar=all_stars&reviewerType=avp_only_reviews&pageNumber=1&sortBy=helpful#reviews-filter-bar)\n",
        "\n",
        "Go to the page above and find some reviews to analyze.\n",
        "\n",
        "### Review Template\n",
        "\n",
        "Here’s our template:"
      ],
      "id": "7622047e-2ce9-4f1e-88a6-4eed32ce9664"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "template =\"\"\"Give a short summary of the following review. The review is placed\n",
        "in the <text> tags. Use no more than 30 words.\n",
        "<text>\n",
        "{review}\n",
        "</text>\"\"\""
      ],
      "id": "c756327c"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### First Review\n",
        "\n",
        "-   Paste your first review where it says CODE below"
      ],
      "id": "e7502786-603f-45cf-b32c-2774ad3cf151"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "first_review = \"\"\"\n",
        "CODE\n",
        "\"\"\""
      ],
      "id": "64ca0fdc"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   Run the below and get summary of the `first_review`"
      ],
      "id": "1f87ea1a-7328-494e-9ad7-f92117cc2da8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt=template.format(review=first_review)\n",
        "response = get_completion(prompt)\n",
        "print_prompt_and_response(prompt, response)"
      ],
      "id": "b1d8c739"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Second Review\n",
        "\n",
        "Lets do the `second_review`"
      ],
      "id": "74a40aec-8e28-4345-b9bc-bdd3019f1f32"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "second_review = \"\"\"\n",
        "CODE\n",
        "\"\"\""
      ],
      "id": "2e1bfade"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   Run the below and get summary of the `second_review`"
      ],
      "id": "49bc2268-a609-4a05-ad57-33f00009ff1d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt=template.format(review=second_review)\n",
        "response = get_completion(prompt)\n",
        "print_prompt_and_response(prompt, response)"
      ],
      "id": "4e1cb550"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Third Review\n",
        "\n",
        "Lets do the `third_review`"
      ],
      "id": "41c07413-2a75-414f-8485-9c0af4457edb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "third_review = \"\"\"\n",
        "CODE\n",
        "\"\"\""
      ],
      "id": "7e7e6ecd"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   Run the below and get summary of the `third_review`"
      ],
      "id": "8891c5c6-9454-4d99-b6df-1097a637a896"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt=template.format(review=third_review)\n",
        "response = get_completion(prompt)\n",
        "print_prompt_and_response(prompt, response)"
      ],
      "id": "24725972"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   Lets do the `third_review`"
      ],
      "id": "10b40eff-8959-4977-aaf8-c24551bd64a0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt=template.format(review=third_review)\n",
        "response = get_completion(prompt)\n",
        "print_prompt_and_response(prompt, response)"
      ],
      "id": "7be85960"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Summarize all Reviews"
      ],
      "id": "ee7d1957-35ca-4077-b0fb-d081b2a57aee"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "template =\"\"\"Summarize all of the following reviews, enclosed in <review> tags.\n",
        "List commonalities between the reviews and differences. If there are issues\n",
        "that multiple customers mention, please list those. If there are things that\n",
        "all customers like, list those. The goal is to summarize the collective\n",
        "viewpoint of the reviews.\n",
        "\n",
        "<review>\n",
        "{first_review}\n",
        "</review>\n",
        "\n",
        "<review>\n",
        "{third_review}\n",
        "</review>\n",
        "\n",
        "<review>\n",
        "{third_review}\n",
        "</review>\n",
        "\"\"\""
      ],
      "id": "d88df931"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt=template.format(first_review=first_review,\n",
        "                       second_review=second_review,\n",
        "                       third_review=third_review)\n",
        "\n",
        "response = get_completion(prompt)\n",
        "print_prompt_and_response(prompt, response)"
      ],
      "id": "60725d4c"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    }
  }
}