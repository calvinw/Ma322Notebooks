{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# More Analyzing Reviews with LLMs\n",
        "\n",
        "### Put Your OPENROUTER_API_KEY here"
      ],
      "id": "0483a2d6-c894-4f21-9db6-0656cc708945"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"OPENROUTER_API_KEY\"] = \"paste_your_api_key_here\""
      ],
      "id": "e198a36b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip3 install langchain langchain_openai"
      ],
      "id": "caab40dc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "try:\n",
        "    model_name\n",
        "except NameError:\n",
        "    model_name=\"openai/gpt-4o-mini\"\n",
        "\n",
        "print(\"Model Name:\", model_name)\n",
        "print(\"Provider:\", \"OpenRouter AI\")\n",
        "\n",
        "llm=ChatOpenAI(model_name=model_name,\n",
        "               openai_api_key=os.environ.get(\"OPENROUTER_API_KEY\"),\n",
        "               openai_api_base=\"https://openrouter.ai/api/v1\")"
      ],
      "id": "2f4b7a16"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import textwrap\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "from IPython.display import display, clear_output, Markdown\n",
        "from ipywidgets import widgets, Layout\n",
        "\n",
        "conversation_output = widgets.Output()\n",
        "messages = []\n",
        "\n",
        "def run_chatbot(system_prompt, initial_message):\n",
        "    global messages \n",
        "    messages = [ {'role':'system', 'content': system_prompt} ]\n",
        "    conversation_output.clear_output()\n",
        "\n",
        "    messages.append({'role': 'assistant', 'content': initial_message})\n",
        "\n",
        "    text_input = widgets.Text(\n",
        "        placeholder='Type your message here...',\n",
        "        layout=widgets.Layout(width='50%')\n",
        "    )\n",
        "    submit_button = widgets.Button(description=\"Send\")\n",
        "\n",
        "    input_box = widgets.HBox([text_input, submit_button])\n",
        "    display(conversation_output, input_box)\n",
        "\n",
        "    def on_submit_click(b):\n",
        "        message = text_input.value\n",
        "        text_input.value = ''  # Clear the input field\n",
        "\n",
        "        with conversation_output:\n",
        "            display(Markdown(f\"**User**: {message}\"))\n",
        "            messages.append({'role': 'user', 'content': message})\n",
        "            response = get_completion_messages(messages)\n",
        "            display(Markdown(f\"**AI**: {response}\"))\n",
        "            messages.append({'role': 'assistant', 'content': response})\n",
        "\n",
        "    submit_button.on_click(on_submit_click)\n",
        "\n",
        "    # Display initial AI message\n",
        "    with conversation_output:\n",
        "        display(Markdown(f\"**AI**: {initial_message}\"))\n",
        "\n",
        "def wrap_text(text, max_width=80):\n",
        "    \"\"\"\n",
        "    Wraps the text to the specified max_width, preserving line breaks and formatting.\n",
        "    \"\"\"\n",
        "    text = text.lstrip()\n",
        "    lines = text.splitlines()  # Split the text into lines\n",
        "    wrapped_lines = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Skip empty lines\n",
        "            wrapped_line = textwrap.fill(line, max_width, initial_indent='', subsequent_indent='')\n",
        "            wrapped_lines.extend(wrapped_line.splitlines())  # Preserve line breaks\n",
        "        else:\n",
        "            wrapped_lines.append('')  # Keep empty lines\n",
        "    return '\\n'.join(wrapped_lines)\n",
        "\n",
        "def print_messages():\n",
        "    for message in messages:\n",
        "        role = message['role']\n",
        "        content = message['content']\n",
        "        \n",
        "        if role == 'system':\n",
        "            print(\"System:\")\n",
        "            print(\"-\" * 40)\n",
        "            print(content)\n",
        "        elif role == 'user':\n",
        "            print(\"User: \", end=\"\")\n",
        "            print(wrap_text(content))\n",
        "        elif role == 'assistant':\n",
        "            print(\"Assistant: \", end=\"\")\n",
        "            print(wrap_text(content))\n",
        "        print()  # Add an extra newline for spacing\n",
        "\n",
        "def print_prompt_and_response(prompt, response):\n",
        "    print(\"Prompt: \")\n",
        "    print(wrap_text(prompt))\n",
        "    print(\"\")\n",
        "    print(\"Response: \")\n",
        "    print(response)\n",
        "\n",
        "def print_messages_and_response(messages, response):\n",
        "    prompt = ChatPromptTemplate(messages=messages)\n",
        "    print_prompt_and_response(prompt.format(), response)\n",
        "\n",
        "def get_completion(prompt, temperature=0.0):\n",
        "    response = llm.invoke(prompt, temperature=temperature)\n",
        "    wrapped_response = wrap_text(response.content)\n",
        "    return wrapped_response\n",
        "\n",
        "def get_completion_messages(messages, temperature=0.0):\n",
        "    response=llm.invoke(messages, temperature=temperature)\n",
        "    wrapped_response = wrap_text(response.content)\n",
        "    return wrapped_response"
      ],
      "id": "aa1376d1"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analyzing Amazon Reviews\n",
        "\n",
        "Lets summarize a few reviews from this product:\n",
        "\n",
        "[Hanes Women’s Slub Knit Full-Zip Hoodie, Textured Cotton Zip-Up T-Shirt\n",
        "Hoodie for\n",
        "Women](https://www.amazon.com/product-reviews/B016YKIF60/ref=cm_cr_arp_d_viewopt_srt?ie=UTF8&filterByStar=all_stars&reviewerType=avp_only_reviews&pageNumber=1&sortBy=helpful#reviews-filter-bar)\n",
        "\n",
        "Go to the page above and find some reviews to analyze.\n",
        "\n",
        "### Review Template\n",
        "\n",
        "Here’s our template:"
      ],
      "id": "f681a0e2-30d3-4c77-a0c0-e2277b8e8141"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "template =\"\"\"Give a short summary of the following review. The review is placed\n",
        "in the <text> tags. Use no more than 30 words.\n",
        "<text>\n",
        "{review}\n",
        "</text>\"\"\""
      ],
      "id": "c115a994"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### First Review\n",
        "\n",
        "**Problem**:\n",
        "\n",
        "-   Paste your first review where it says CODE below"
      ],
      "id": "5794b0be-ac2c-4aab-93bc-94d98f32ef65"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "first_review = \"\"\"\n",
        "CODE\n",
        "\"\"\""
      ],
      "id": "a9ccc1e0"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   Run the below and get summary of the `first_review`"
      ],
      "id": "f1fbbd88-a34d-4ceb-bfab-3e45b87e2c2a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt=template.format(review=first_review)\n",
        "response = get_completion(prompt)\n",
        "print_prompt_and_response(prompt, response)"
      ],
      "id": "ca185433"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Second Review\n",
        "\n",
        "**Problem**:\n",
        "\n",
        "Lets do the `second_review`"
      ],
      "id": "1239c259-238e-4f51-9505-5d135965cf21"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "second_review = \"\"\"\n",
        "CODE\n",
        "\"\"\""
      ],
      "id": "73c439b3"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   Run the below and get summary of the `second_review`"
      ],
      "id": "2bca9860-4b44-42cf-ace4-35430c2c8e74"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt=template.format(review=second_review)\n",
        "response = get_completion(prompt)\n",
        "print_prompt_and_response(prompt, response)"
      ],
      "id": "72e6bc99"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Third Review\n",
        "\n",
        "**Problem**:\n",
        "\n",
        "Lets do the `third_review`"
      ],
      "id": "a2d7b92d-b8f6-4284-8b6b-8d8778a1f990"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "third_review = \"\"\"\n",
        "CODE\n",
        "\"\"\""
      ],
      "id": "e5c4087e"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   Run the below and get summary of the `third_review`"
      ],
      "id": "de4b011d-f25e-40c4-be48-21b436046f1c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt=template.format(review=third_review)\n",
        "response = get_completion(prompt)\n",
        "print_prompt_and_response(prompt, response)"
      ],
      "id": "ecea9186"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Summarize all Reviews"
      ],
      "id": "04c96ff3-44e6-4f43-9397-a3d9cb7bcf4b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "template =\"\"\"Summarize all of the following reviews, enclosed in <review> tags.\n",
        "List commonalities between the reviews and differences. If there are issues\n",
        "that multiple customers mention, please list those. If there are things that\n",
        "all customers like, list those. The goal is to summarize the collective\n",
        "viewpoint of the reviews.\n",
        "\n",
        "<review>\n",
        "{first_review}\n",
        "</review>\n",
        "\n",
        "<review>\n",
        "{third_review}\n",
        "</review>\n",
        "\n",
        "<review>\n",
        "{third_review}\n",
        "</review>\n",
        "\"\"\""
      ],
      "id": "2b1ded53"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt=template.format(first_review=first_review,\n",
        "                       second_review=second_review,\n",
        "                       third_review=third_review)\n",
        "\n",
        "response = get_completion(prompt)\n",
        "print_prompt_and_response(prompt, response)"
      ],
      "id": "2a758212"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    }
  }
}