{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# More Simple LLM Chain"
      ],
      "id": "18e56f00-aab0-48b1-8ce5-d673f955a943"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "if os.environ.get(\"TOGETHER_API_KEY\") is None:\n",
        "   os.environ[\"TOGETHER_API_KEY\"] = \"paste_your_api_key_here\""
      ],
      "id": "7dd9cb9b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup the LLM"
      ],
      "id": "229239bc-7263-4b07-9614-0e95884374a5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip3 install langchain langchain_openai"
      ],
      "id": "58dce349"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "#model_name = \"NousResearch/Nous-Hermes-2-Mixtral-8x7B-SFT\"\n",
        "#model_name = \"NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO\"\n",
        "#model_name=\"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
        "#model_name=\"mistralai/Mistral-7B-Instruct-v0.1\"\n",
        "#model_name=\"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "#model_name = \"openchat/openchat-3.5-1210\"\n",
        "#model_name = \"Qwen/Qwen1.5-72B-Chat\"\n",
        "model_name = \"cognitivecomputations/dolphin-2.5-mixtral-8x7b\"\n",
        "\n",
        "print(\"Provider: TogetherAI\")\n",
        "print(\"Model: \" + model_name)\n",
        "\n",
        "llm=ChatOpenAI(model_name=model_name,\n",
        "               openai_api_key=os.environ.get(\"TOGETHER_API_KEY\"),\n",
        "               openai_api_base=\"https://api.together.xyz/v1/\")"
      ],
      "id": "8a9a6f63"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import textwrap\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "def wrap_text(text, max_width=80):\n",
        "    \"\"\"\n",
        "    Wraps the text to the specified max_width, preserving line breaks and formatting.\n",
        "    \"\"\"\n",
        "    text = text.lstrip()\n",
        "    lines = text.splitlines()  # Split the text into lines\n",
        "    wrapped_lines = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Skip empty lines\n",
        "            wrapped_line = textwrap.fill(line, max_width, initial_indent='', subsequent_indent='')\n",
        "            wrapped_lines.extend(wrapped_line.splitlines())  # Preserve line breaks\n",
        "        else:\n",
        "            wrapped_lines.append('')  # Keep empty lines\n",
        "    return '\\n'.join(wrapped_lines)\n",
        "\n",
        "def print_prompt_and_response(prompt, response):\n",
        "    print(\"Prompt: \")\n",
        "    print(wrap_text(prompt))\n",
        "    print(\"\")\n",
        "    print(\"Response: \")\n",
        "    print(response)\n",
        "\n",
        "def print_messages_and_response(messages, response):\n",
        "    prompt = ChatPromptTemplate(messages=messages)\n",
        "    print_prompt_and_response(prompt.format(), response)\n",
        "\n",
        "def get_completion(prompt, temperature=0.0):\n",
        "    response = llm.invoke(prompt, temperature=temperature)\n",
        "    wrapped_response = wrap_text(response.content)\n",
        "    return wrapped_response\n",
        "\n",
        "def get_completion_messages(messages, temperature=0.0):\n",
        "    response=llm.invoke(messages, temperature=temperature)\n",
        "    wrapped_response = wrap_text(response.content)\n",
        "    return wrapped_response"
      ],
      "id": "446a01bb"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Suggest a Company Name and Upper It\n",
        "\n",
        "### Step 1: Suggest a Funny Company Name\n",
        "\n",
        "Lets start by creating a variable for our product request."
      ],
      "id": "3f4a5a4e-27ee-4103-b240-b6aa456cb1b0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "car = \"sports cars\""
      ],
      "id": "430a8ce1"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   Write a prompt template that has the LLM suggest one funny name for\n",
        "    a company that makes a certain product.\n",
        "-   Make `product` a template variable and use `{product}` in your\n",
        "    template"
      ],
      "id": "8955ec17-4783-4bfa-825c-e2ccb28e76e9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "company_template =\"\"\"\n",
        "\n",
        "CODE\n",
        "\n",
        "\"\"\""
      ],
      "id": "44ff2d05"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   Pass `car` to the format function as the template variable\n",
        "    `{product}`\n",
        "-   Pass the `company_prompt` to `get_completion` to get the LLM’s\n",
        "    response\n",
        "-   Print the `company_response`"
      ],
      "id": "28e48940-1e7a-4b1e-9f93-eb680c7402c5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "company_prompt = company_template.format(product=CODE)\n",
        "company_response = get_completion(CODE)\n",
        "print(CODE)"
      ],
      "id": "0a33a27b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2: Upper Case the Name and Product\n",
        "\n",
        "Upper case the company\n",
        "\n",
        "-   Write a prompt template using both `{product}` and `{company}` as\n",
        "    template variables, asking the LLM to upper case the company name\n",
        "    and the product"
      ],
      "id": "6ef03ef7-ae89-407b-940d-4023f7867d60"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "uppercase_template =\"\"\"\n",
        "\n",
        "CODE\n",
        "\n",
        "\"\"\""
      ],
      "id": "f357b247"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   Pass the `company_response` as the `company` variable and `car` as\n",
        "    the `product` variable\n",
        "-   Pass the `uppercase_prompt` to `get_completion` to get the LLM’s\n",
        "    response Print the `uppercase_response`"
      ],
      "id": "574d5efc-8d0b-4e27-9519-f9add6a918be"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "uppercase_prompt = uppercase_template.format(company=CODE,\n",
        "                                             product=CODE)\n",
        "uppercase_response = get_completion(CODE)\n",
        "print(CODE)"
      ],
      "id": "dd4c5a54"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Final Report"
      ],
      "id": "f1aab553-47d7-4c3b-931f-3271736231c5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "report_template = \"\"\"\n",
        "## Final Report\n",
        "\n",
        "### Product\n",
        "{product}\n",
        "\n",
        "### Company Name\n",
        "{company}\n",
        "\n",
        "### Upper Cased Company and Product\n",
        "{uppercase}\n",
        "\"\"\"\n",
        "\n",
        "report = report_template.format(product = car,\n",
        "                         company = company_response,\n",
        "                         uppercase = uppercase_response)\n",
        "print(report)"
      ],
      "id": "de5a1260"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    }
  }
}