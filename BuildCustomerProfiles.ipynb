{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Build Customer Profiles"
      ],
      "id": "6ba2c3c8-2c54-40b8-95ec-23192d1b869e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Please set up your OPENROUTER_API_KEY\n",
        "if os.environ.get(\"OPENROUTER_API_KEY\") is None:\n",
        "   os.environ[\"OPENROUTER_API_KEY\"] = \"paste_your_api_key_here\""
      ],
      "id": "0caa7dd5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip3 install langchain langchain_openai"
      ],
      "id": "a0836eea"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "#model_name = \"mistralai/mistral-7b-instruct:free\"\n",
        "#model_name=\"openai/gpt-4\"\n",
        "#model_name=\"openai/gpt-3.5-turbo\"\n",
        "#model_name=\"mistralai/mistral-medium\"\n",
        "#model_name=\"mistralai/mistral-large\"\n",
        "#model_name=\"mistralai/mixtral-8x7b-instruct\"\n",
        "model_name=\"anthropic/claude-3-haiku\"\n",
        "#model_name=\"anthropic/claude-3-sonnet\"\n",
        "#model_name=\"anthropic/claude-3-opus\"\n",
        "#model_name=\"openchat/openchat-7b:free\"\n",
        "#model_name=\"openchat/openchat-7b\"\n",
        "#model_name=\"databricks/dbrx-instruct\"\n",
        "\n",
        "print(\"Provider: Open Router\")\n",
        "print(\"Model: \", model_name)\n",
        "\n",
        "llm=ChatOpenAI(model_name=model_name,\n",
        "               openai_api_key=os.environ.get(\"OPENROUTER_API_KEY\"),\n",
        "               openai_api_base=\"https://openrouter.ai/api/v1\")"
      ],
      "id": "f5778f9e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import textwrap\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "def wrap_text(text, max_width=80):\n",
        "    \"\"\"\n",
        "    Wraps the text to the specified max_width, preserving line breaks and formatting.\n",
        "    \"\"\"\n",
        "    text = text.lstrip()\n",
        "    lines = text.splitlines()  # Split the text into lines\n",
        "    wrapped_lines = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Skip empty lines\n",
        "            wrapped_line = textwrap.fill(line, max_width, initial_indent='', subsequent_indent='')\n",
        "            wrapped_lines.extend(wrapped_line.splitlines())  # Preserve line breaks\n",
        "        else:\n",
        "            wrapped_lines.append('')  # Keep empty lines\n",
        "    return '\\n'.join(wrapped_lines)\n",
        "\n",
        "def print_prompt_and_response(prompt, response):\n",
        "    print(\"Prompt: \")\n",
        "    print(wrap_text(prompt))\n",
        "    print(\"\")\n",
        "    print(\"Response: \")\n",
        "    print(response)\n",
        "\n",
        "def print_messages_and_response(messages, response):\n",
        "    prompt = ChatPromptTemplate(messages=messages)\n",
        "    print_prompt_and_response(prompt.format(), response)\n",
        "\n",
        "def get_completion(prompt, temperature=0.0):\n",
        "    response = llm.invoke(prompt, temperature=temperature)\n",
        "    wrapped_response = wrap_text(response.content)\n",
        "    return wrapped_response\n",
        "\n",
        "def get_completion_messages(messages, temperature=0.0):\n",
        "    response=llm.invoke(messages, temperature=temperature)\n",
        "    wrapped_response = wrap_text(response.content)\n",
        "    return wrapped_response"
      ],
      "id": "00698fa3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "info=\"\"\"\n",
        "Fitbit Versa 2 Smartwatch - $149.95\n",
        "Yoga mat - $29.99\n",
        "Blender (NutriBullet) - $79.99\n",
        "Organic protein powder - $24.99 (for 2lb tub)\n",
        "Reusable water bottle - $19.95\n",
        "Noise-canceling headphones (Sony WH-1000XM4) - $348.00\n",
        "Kindle Paperwhite e-reader - $139.99\n",
        "Gardening tools (pruning shears, trowel, gloves) - $39.97\n",
        "Outdoor camping backpack - $89.95\n",
        "Hiking boots - $124.99\n",
        "Travel luggage set (3-piece) - $149.99\n",
        "Language learning software (Babbel subscription) - $12.95/month\n",
        "Cooking utensil set (10-piece) - $39.99\n",
        "Cast iron skillet - $24.99\n",
        "Subscription box (Keto snack box) - $38.00/month\n",
        "\"\"\""
      ],
      "id": "5dcfb968"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt = \"\"\"\n",
        "You are an AI assistant tasked with generating a customer profile based on the\n",
        "following list of recent products purchased by a customer. The list includes\n",
        "the product name and price:\n",
        "\n",
        "{customer_info}\n",
        "\n",
        "Using this information, provide a detailed customer profile that includes:\n",
        "\n",
        "Potential demographic details (age range, gender, location, household\n",
        "status) Interests and lifestyle (hobbies, activities, diet/health\n",
        "preferences) Income and spending habits (budget range, willingness to pay\n",
        "for certain products/services) Recommendations for other products/services\n",
        "this customer may be interested in based on their purchases Your response\n",
        "should be well-structured, providing the requested details in separate\n",
        "sections. Avoid making assumptions that cannot be reasonably inferred from\n",
        "the provided data.\n",
        "\"\"\""
      ],
      "id": "f4e61308"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt = prompt.format(customer_info = info)\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "id": "ae945322"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    }
  }
}